#    (Run install.packages() once, then comment it out)
install.packages(c("tidycensus", "sf", "dplyr", "readr", "stringr", "stats"))
library(stats)
library(tidycensus)   # to pull ACS data
library(sf)           # to work with shapefiles & spatial joins
library(dplyr)        # for data wrangling (filter/join/etc)
library(readr)        # to read/write CSVs
library(stringr)      # for string helpers
# 1) Set your Census API key
#    You only need to do this once per computer.
#    Replace "YOUR_KEY" with the key you got at https://api.census.gov/data/key_signup.html
census_api_key(CENSUS_API_KEY, install = TRUE, overwrite = TRUE)
# 0) Install & load needed packages
#    (Run install.packages() once, then comment it out)
install.packages(c("tidycensus", "sf", "dplyr", "readr", "stringr", "stats"))
library(stats)
# 0) Install & load needed packages
#    (Run install.packages() once, then comment it out)
install.packages(c("tidycensus", "sf", "dplyr", "readr", "stringr", "stats"))
library(stats)
library(stats)
library(stats)
library(stats)
stats
library(stats)
Sys.getenv("CENSUS_API_KEY")
file.edit("~/.Renviron")
file.edit("~/.Renviron")
Sys.getenv("CENSUS_API_KEY")
Sys.getenv("CENSUS_API_KEY")
# 0) Install & load needed packages
#    (Run install.packages() once, then comment it out)
install.packages(c("tidycensus", "sf", "dplyr", "readr", "stringr", "stats"))
library(stats)
library(tidycensus)   # to pull ACS data
library(sf)           # to work with shapefiles & spatial joins
library(dplyr)        # for data wrangling (filter/join/etc)
library(readr)        # to read/write CSVs
library(stringr)      # for string helpers
# 1) Set your Census API key
#    You only need to do this once per computer.
#    Replace "YOUR_KEY" with the key you got at https://api.census.gov/data/key_signup.html
census_api_key(CENSUS_API_KEY, install = TRUE, overwrite = TRUE)
# 7) Find which block group each lot belongs to
#    st_join(..., join = st_within) does a point‚Äêin‚Äêpolygon match.
message("üîÑ Joining lots to block groups‚Ä¶")
# 0) Install & load needed packages
#    (Run install.packages() once, then comment it out)
install.packages(c("tidycensus", "sf", "dplyr", "readr", "stringr", "stats"))
library(stats)
library(tidycensus)   # to pull ACS data
library(sf)           # to work with shapefiles & spatial joins
library(dplyr)        # for data wrangling (filter/join/etc)
library(readr)        # to read/write CSVs
library(stringr)      # for string helpers
# 1) pull the key from your already-correct ~/.Renviron
my_key <- Sys.getenv("CENSUS_API_KEY")
if (my_key == "") stop("üîë CENSUS_API_KEY not set in your environment")
# 2) register it for this session only‚Äîdo NOT overwrite .Renviron
census_api_key(my_key, install = FALSE)
# 3) Define which ACS variables you want
#    These codes come from the ACS codebook: load_variables() can help you find them.
#    - B01003_001 = total population
#    - B19013_001 = median household income
#    - B17001_002 = count below poverty level
vars <- c(
pop_tot    = "B01003_001",
med_income = "B19013_001",
pov_count  = "B17001_002"
)
# 4) Download ACS block‚Äêgroup data with geometry
#    This pulls both the numbers and the shapes of each block group.
message("üîÑ Downloading ACS block-group data‚Ä¶")
acs_bg <- get_acs(
geography = "block group",
variables = vars,
year      = 2019,       # use the 2019 5-year survey
output    = "wide",     # wide format gives one column per var
geometry  = TRUE        # include spatial shapes
)
# 0) Install & load needed packages
#    (Run install.packages() once, then comment it out)
install.packages(c("tidycensus", "sf", "dplyr", "readr", "stringr", "stats"))
library(stats)
library(tidycensus)   # to pull ACS data
library(sf)           # to work with shapefiles & spatial joins
library(dplyr)        # for data wrangling (filter/join/etc)
library(readr)        # to read/write CSVs
library(stringr)      # for string helpers
# 1) pull the key from your already-correct ~/.Renviron
my_key <- Sys.getenv("CENSUS_API_KEY")
if (my_key == "") stop("üîë CENSUS_API_KEY not set in your environment")
# 2) register it for this session only‚Äîdo NOT overwrite .Renviron
census_api_key(my_key, install = FALSE)
# 3) Define which ACS variables you want
#    These codes come from the ACS codebook: load_variables() can help you find them.
#    - B01003_001 = total population
#    - B19013_001 = median household income
#    - B17001_002 = count below poverty level
vars <- c(
pop_tot    = "B01003_001",
med_income = "B19013_001",
pov_count  = "B17001_002"
)
# 4) Download ACS block‚Äêgroup data with geometry
#    This pulls both the numbers and the shapes of each block group.
message("üîÑ Downloading ACS block-group data‚Ä¶")
acs_bg <- get_acs(
geography = "block group",
variables = vars,
year      = 2019,       # use the 2019 5-year survey
output    = "wide",     # wide format gives one column per var
geometry  = TRUE        # include spatial shapes
)
# 0) Install & load needed packages (run install.packages() once, then comment it out)
# install.packages(c("tidycensus", "sf", "dplyr", "readr", "stringr"))
library(tidycensus)   # to pull ACS data
library(sf)           # to work with spatial data
library(dplyr)        # for data wrangling (filter/join/etc)
library(readr)        # to read/write CSVs
library(stringr)      # for string helper functions
# 1) Load your Census API key from environment
my_key <- Sys.getenv("CENSUS_API_KEY")
if (my_key == "") {
stop("üîë CENSUS_API_KEY not found. Make sure it's set in ~/.Renviron")
}
# Register it for this session only (do NOT overwrite your .Renviron)
census_api_key(my_key, install = FALSE)
# 2) Define which ACS variables to pull (2019 5-year)
#    - B01003_001 = total population
#    - B19013_001 = median household income
#    - B17001_002 = count below poverty level
vars <- c(
pop_tot    = "B01003_001",
med_income = "B19013_001",
pov_count  = "B17001_002"
)
# 3) Download ACS block-group data with geometry for just NYC‚Äôs five boroughs
message("üîÑ Downloading ACS block-group data for NYC‚Ä¶")
acs_bg <- get_acs(
geography = "block group",
variables = vars,
year      = 2019,       # use the 2019 5-year survey
state     = "NY",       # limit to New York
county    = c("Bronx", "Kings", "New York", "Queens", "Richmond"),
output    = "wide",     # wide format: one column per var
geometry  = TRUE        # include spatial shapes
)
# 4) Read your PLUTO shapefile (MapPLUTO.shp)
message("üîÑ Reading PLUTO parcels (MapPLUTO.shp)‚Ä¶")
bbl_sf <- st_read("data/raw/MapPLUTO.shp") %>%
st_transform(crs = st_crs(acs_bg))  # match CRS to the ACS data
# 5) Compute centroids of each lot polygon
message("üîÑ Computing centroids of each lot‚Ä¶")
bbl_centroids <- st_centroid(bbl_sf)
View(acs_bg)
View(bbl_sf)
# 0) Install & load needed packages (run install.packages() once, then comment it out)
# install.packages(c("tidycensus", "sf", "dplyr", "readr", "stringr"))
library(tidycensus)   # to pull ACS data
library(sf)           # to work with spatial data
library(dplyr)        # for data wrangling (filter/join/etc)
library(readr)        # to read/write CSVs
library(stringr)      # for string helper functions
# 1) Load your Census API key from environment
my_key <- Sys.getenv("CENSUS_API_KEY")
if (my_key == "") {
stop("üîë CENSUS_API_KEY not found. Make sure it's set in ~/.Renviron")
}
# Register it for this session only (do NOT overwrite your .Renviron)
census_api_key(my_key, install = FALSE)
# 2) Define which ACS variables to pull (2019 5-year)
#    - B01003_001 = total population
#    - B19013_001 = median household income
#    - B17001_002 = count below poverty level
vars <- c(
pop_tot    = "B01003_001",
med_income = "B19013_001",
pov_count  = "B17001_002"
)
# 3) Download ACS block-group data with geometry for just NYC‚Äôs five boroughs
message("üîÑ Downloading ACS block-group data for NYC‚Ä¶")
acs_bg <- get_acs(
geography = "block group",
variables = vars,
year      = 2019,       # use the 2019 5-year survey
state     = "NY",       # limit to New York
county    = c("Bronx", "Kings", "New York", "Queens", "Richmond"),
output    = "wide",     # wide format: one column per var
geometry  = TRUE        # include spatial shapes
)
# 4) Read & project PLUTO parcels
bbl_sf <- st_read("data/raw/MapPLUTO.shp") %>%
st_transform(crs = st_crs(acs_bg))
# 4b) Repair invalid geometries
if (!all(st_is_valid(bbl_sf))) {
message("üîß Repairing invalid geometries‚Ä¶")
bbl_sf <- st_make_valid(bbl_sf)
}
# 5) Compute centroids
message("üîÑ Computing centroids of each lot‚Ä¶")
bbl_centroids <- st_centroid(bbl_sf)
# 6) Join lots to ACS block‚Äêgroups
message("üîÑ Joining lots to block groups‚Ä¶")
acs_by_bbl <- st_join(
bbl_centroids,
acs_bg %>% select(GEOID, ends_with("E")),
join = st_within
) %>%
st_drop_geometry() %>%
rename_with(~ str_remove(.x, "E$"), ends_with("E")) %>%
select(BBL, pop_tot, med_income, pov_count)
# 7) Write out the ACS-by-BBL table for the spatial-join step
message("üîÑ Writing ACS√óBBL table to data/raw/ACS.csv‚Ä¶")
write_csv(acs_by_bbl, "data/raw/ACS.csv")
message("‚úÖ Done! ACS table has ", nrow(acs_by_bbl), " lots with covariates.")
Sys.getenv("CENSUS_API_KEY")
View(acs_by_bbl)
View(acs_bg)
View(bbl_centroids)
View(acs_by_bbl)
library(dplyr)
acs_by_bbl %>%
summarise(total_pop = sum(pop_tot, na.rm = TRUE))
View(acs_bg)
# 1) Load packages
library(dplyr)
library(readr)
# 2) Read your ACS√óBBL table (must include GEOID and pop_tot)
acs_by_bbl <- read_csv("data/raw/ACS.csv")
# 3) Pick one row per block group and sum its population
total_pop <- acs_by_bbl %>%
distinct(GEOID, pop_tot) %>%                # one row per GEOID
summarise(total_pop = sum(pop_tot, na.rm=TRUE)) %>%
pull(total_pop)
# 0) Install & load packages (run install.packages() once, then comment it out)
install.packages(c("vroom", "dplyr", "stringr", "lubridate", "readr"))
library(vroom)
library(dplyr)
library(stringr)
library(lubridate)
library(readr)
# 1) Path to raw 311 data
data_path <- "data/raw/311_Service_Requests_from_2010_to_Present_20250526.csv"
# 2) Preview 5 000 rows to confirm columns
rats_5k_sample <- vroom(
file      = data_path,
n_max     = 5000,
col_select = c(
"Unique Key", "Created Date", "Closed Date", "Status",
"Resolution Description", "Location Type",
"Incident Zip", "Borough", "BBL",
"Latitude", "Longitude", "Descriptor"
)
)
# Inspect
print(head(rats_5k_sample, 5))
print(names(rats_5k_sample))
# 3) Parse dates, flag bad closes (pre-2010), compute days_open as of 2025-05-26,
#    and also flag stale_open if days_open > 365
# a) Define your fixed sentinel & snapshot dates
sentinel_date <- as_datetime("2010-01-01 00:00:00")  # anything before this is bogus
snapshot_date <- as.Date("2025-05-26")               # cut-off for still-open
rats_clean <- vroom(
file       = data_path,
col_select = c(
"Unique Key", "Created Date", "Closed Date", "Status",
"Resolution Description", "Location Type",
"Incident Zip", "Borough", "BBL",
"Latitude", "Longitude", "Descriptor"
),
col_types = cols(
`Unique Key`             = col_character(),
`Created Date`           = col_character(),
`Closed Date`            = col_character(),
Status                   = col_character(),
`Resolution Description` = col_character(),
`Location Type`          = col_character(),
`Incident Zip`           = col_character(),
Borough                  = col_character(),
BBL                      = col_character(),
Latitude                 = col_double(),
Longitude                = col_double(),
Descriptor               = col_character()
)
) %>%
mutate(
# parse raw strings
created_dt    = mdy_hms(`Created Date`),
closed_dt_raw = mdy_hms(`Closed Date`),
# flag any closed before sentinel_date
bad_close     = closed_dt_raw < sentinel_date,
# recode closed_dt: NA if bad_close or truly missing
closed_dt     = if_else(bad_close, NA_POSIXct_, closed_dt_raw),
# compute days_open: real closes vs snapshot for pending
days_open     = as.numeric(
if_else(
!is.na(closed_dt),
difftime(closed_dt, created_dt, units = "days"),
difftime(snapshot_date, as.Date(created_dt), units = "days")
),
units = "days"
),
# flag extremely long‚Äêopen tickets (> 365 days)
stale_open    = days_open > 365,
# classify event type for modeling later
event_type = case_when(
str_detect(Descriptor, regex("sighting",   ignore_case = TRUE)) ~ "direct",
str_detect(Descriptor, regex("dropp|burrow",ignore_case = TRUE)) ~ "sign",
TRUE                                                            ~ "other"
)
) %>%
# keep only the fields we need
select(
`Unique Key`, created_dt, closed_dt, days_open,
bad_close, stale_open, event_type,
Status, `Resolution Description`,
`Location Type`, `Incident Zip`, Borough, BBL,
Latitude, Longitude, Descriptor
) %>%
# filter to your rodent-related reports
filter(
str_starts(Descriptor, regex("Rat|Rodent|Mouse",   ignore_case = TRUE)) |
str_detect(Descriptor,   regex("dropp|burrow|bait|nest|runway|gnaw", ignore_case = TRUE))
)
# 0) Install & load packages (run install.packages() once, then comment it out)
install.packages(c("vroom", "dplyr", "stringr", "lubridate", "readr"))
library(vroom)
# 0) Install & load packages (run install.packages() once, then comment it out)
install.packages(c("vroom", "dplyr", "stringr", "lubridate", "readr"))
library(vroom)
# In a fresh R console (no packages loaded), try:
library(stats)
library(stats)
# 0) Install & load packages (run install.packages() once, then comment it out)
install.packages(c("vroom", "dplyr", "stringr", "lubridate", "readr"))
library(vroom)
# 0) Install & load packages (run install.packages() once, then comment it out)
install.packages(c("vroom", "dplyr", "stringr", "lubridate", "readr"))
library(vroom)
# In a fresh R console (no packages loaded), try:
library(stats)
# 0) Install & load packages (run install.packages() once, then comment it out)
install.packages(c("vroom", "dplyr", "stringr", "lubridate", "readr"))
library(vroom)
# 0) Install & load packages (run install.packages() once, then comment it out)
install.packages(c("vroom", "dplyr", "stringr", "lubridate", "readr"))
library(vroom)
library(dplyr)
library(stringr)
library(lubridate)
library(readr)
# 1) Path to raw 311 data
data_path <- "data/raw/311_Service_Requests_from_2010_to_Present_20250526.csv"
# 2) Preview 5 000 rows to confirm columns
rats_5k_sample <- vroom(
file      = data_path,
n_max     = 5000,
col_select = c(
"Unique Key", "Created Date", "Closed Date", "Status",
"Resolution Description", "Location Type",
"Incident Zip", "Borough", "BBL",
"Latitude", "Longitude", "Descriptor"
)
)
# Inspect
print(head(rats_5k_sample, 5))
print(names(rats_5k_sample))
# 3) Parse dates, flag bad closes (pre-2010), compute days_open as of 2025-05-26,
#    and also flag stale_open if days_open > 365
# a) Define your fixed sentinel & snapshot dates
sentinel_date <- as_datetime("2010-01-01 00:00:00")  # anything before this is bogus
snapshot_date <- as.Date("2025-05-26")               # cut-off for still-open
rats_clean <- vroom(
file       = data_path,
col_select = c(
"Unique Key", "Created Date", "Closed Date", "Status",
"Resolution Description", "Location Type",
"Incident Zip", "Borough", "BBL",
"Latitude", "Longitude", "Descriptor"
),
col_types = cols(
`Unique Key`             = col_character(),
`Created Date`           = col_character(),
`Closed Date`            = col_character(),
Status                   = col_character(),
`Resolution Description` = col_character(),
`Location Type`          = col_character(),
`Incident Zip`           = col_character(),
Borough                  = col_character(),
BBL                      = col_character(),
Latitude                 = col_double(),
Longitude                = col_double(),
Descriptor               = col_character()
)
) %>%
mutate(
# parse raw strings
created_dt    = mdy_hms(`Created Date`),
closed_dt_raw = mdy_hms(`Closed Date`),
# flag any closed before sentinel_date
bad_close     = closed_dt_raw < sentinel_date,
# recode closed_dt: NA if bad_close or truly missing
closed_dt     = if_else(bad_close, NA_POSIXct_, closed_dt_raw),
# compute days_open: real closes vs snapshot for pending
days_open     = as.numeric(
if_else(
!is.na(closed_dt),
difftime(closed_dt, created_dt, units = "days"),
difftime(snapshot_date, as.Date(created_dt), units = "days")
),
units = "days"
),
# flag extremely long‚Äêopen tickets (> 365 days)
stale_open    = days_open > 365,
# classify event type for modeling later
event_type = case_when(
str_detect(Descriptor, regex("sighting",   ignore_case = TRUE)) ~ "direct",
str_detect(Descriptor, regex("dropp|burrow",ignore_case = TRUE)) ~ "sign",
TRUE                                                            ~ "other"
)
) %>%
# keep only the fields we need
select(
`Unique Key`, created_dt, closed_dt, days_open,
bad_close, stale_open, event_type,
Status, `Resolution Description`,
`Location Type`, `Incident Zip`, Borough, BBL,
Latitude, Longitude, Descriptor
) %>%
# filter to your rodent-related reports
filter(
str_starts(Descriptor, regex("Rat|Rodent|Mouse",   ignore_case = TRUE)) |
str_detect(Descriptor,   regex("dropp|burrow|bait|nest|runway|gnaw", ignore_case = TRUE))
)
# 4) Final check
message("‚úÖ Clean & flagged: ", nrow(rats_clean), " rows; ",
sum(rats_clean$bad_close), " bad_close, ",
sum(rats_clean$stale_open), " stale_open")
glimpse(rats_clean)
# 5) Export cleaned rats dataset
write_csv(
rats_clean,
"data/processed/rats_clean.csv"
)
message("‚úèÔ∏è Saved rats_clean.csv to data/processed/")
# 0) Install & load needed packages (once; then comment install.packages)
# install.packages(c("tidycensus", "sf", "dplyr", "readr", "stringr"))
library(tidycensus)   # to pull ACS data
library(sf)           # spatial tools for centroids
library(dplyr)        # data wrangling
library(readr)        # CSV I/O
library(stringr)      # string helpers
# 1) Load your Census API key from ~/.Renviron
my_key <- Sys.getenv("CENSUS_API_KEY")
if (my_key == "") stop("üîë CENSUS_API_KEY not found in ~/.Renviron")
census_api_key(my_key, install = FALSE)
# 2) Define ACS variables (2019 5-year)
vars <- c(
pop_tot    = "B01003_001",  # total population
med_income = "B19013_001",  # median household income
pov_count  = "B17001_002"   # count below poverty
)
# 3) Download ACS block-group data (with geometry)
message("üîÑ Downloading ACS block-group data for NYC‚Ä¶")
acs_bg <- get_acs(
geography = "block group",
variables = vars,
year      = 2019,
state     = "NY",
county    = c("Bronx", "Kings", "New York", "Queens", "Richmond"),
output    = "wide",
geometry  = TRUE
)
# 4) Read & project PLUTO parcels
message("üîÑ Reading PLUTO parcels (MapPLUTO.shp)‚Ä¶")
bbl_sf <- st_read("data/raw/MapPLUTO.shp") %>%
st_transform(crs = st_crs(acs_bg))
# 4b) Repair any invalid geometries so centroids will compute
if (!all(st_is_valid(bbl_sf))) {
message("üîß Repairing invalid geometries‚Ä¶")
bbl_sf <- sf::st_make_valid(bbl_sf)
}
# 5) Compute centroids of each lot
message("üîÑ Computing centroids of each lot‚Ä¶")
bbl_centroids <- st_centroid(bbl_sf)
# 6) Spatial‚Äêjoin each lot to its block‚Äêgroup, keep GEOID + estimates
message("üîÑ Joining lots to block groups‚Ä¶")
acs_by_bbl <- st_join(
bbl_centroids,
acs_bg %>% select(GEOID, ends_with("E")),
join = st_within
) %>%
st_drop_geometry() %>%
rename_with(~ str_remove(.x, "E$"), ends_with("E")) %>%
select(
BBL,        # tax-lot ID
GEOID,      # block-group ID
pop_tot,    # total population
med_income, # median household income
pov_count   # count below poverty
)
# 7) Write out the ACS-by-BBL table
message("üîÑ Writing ACS√óBBL table to data/raw/ACS.csv‚Ä¶")
write_csv(acs_by_bbl, "data/raw/ACS.csv")
# 8) Sanity check: sum each block-group‚Äôs pop_tot exactly once
total_pop <- acs_by_bbl %>%
distinct(GEOID, pop_tot) %>%
summarise(total_pop = sum(pop_tot, na.rm = TRUE)) %>%
pull(total_pop)
message("‚úÖ Done! ACS table has ", nrow(acs_by_bbl),
" lots; sum of unique block-group pop_tot = ", total_pop)
