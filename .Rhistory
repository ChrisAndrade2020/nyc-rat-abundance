state     = "NY",
county    = c("Bronx", "Kings", "New York", "Queens", "Richmond"),
output    = "wide",
geometry  = TRUE
) %>%
rename_with(~ str_remove(.x, "E$"), ends_with("E")) %>%  # drop trailing E
select(GEOID, pop_tot, med_income, pov_count) %>%
st_transform(crs = 4326)  # match rat points (WGS84)
## 2) Load enriched rat points --------------------------------------------------
message("üì•  Reading rats_enriched.geojson ‚Ä¶")
rats <- st_read("output/rats_enriched.geojson", quiet = TRUE)
## 3) Spatial join rats ‚Üí block groups -----------------------------------------
message("üîó  Joining rat points to BGs ‚Ä¶")
rat_bg_join <- st_join(
rats,
acs_bg,
join = st_intersects,  # includes boundary‚Äëtouching points
left = TRUE
) %>%
rename_with(~ str_remove(.x, "\\.y$"), ends_with(".y")) %>%  # keep clean names
select(-ends_with(".x"))
## 4) Write point‚Äëlevel CSV -----------------------------------------------------
rat_bg_point_df <- st_drop_geometry(rat_bg_join)
write_csv(rat_bg_point_df, "output/rat_with_bg_ACS_point.csv")
message("‚úÖ  Saved point‚Äëlevel rat+ACS ‚Üí output/rat_with_bg_ACS_point.csv (",
scales::comma(nrow(rat_bg_point_df)), " rows)")
## 5) Summarise by block group --------------------------------------------------
message("üìä  Building BG‚Äëlevel summary ‚Ä¶")
bg_summary <- rat_bg_point_df %>%
group_by(GEOID) %>%
summarise(
calls      = n(),
pop_tot    = first(pop_tot),    # identical within BG
med_income = first(med_income),
pov_count  = first(pov_count)
) %>%
ungroup() %>%
mutate(rate_per_10k = calls / pop_tot * 10000)
write_csv(bg_summary, "output/bg_calls_ACS_summary.csv")
message("‚úÖ  Saved BG summary ‚Üí output/bg_calls_ACS_summary.csv (",
scales::comma(nrow(bg_summary)), " rows)")
View(rat_sf)
View(rat_sf)
View(rats)
View(acs_by_bbl)
View(acs)
View(acs_by_bbl)
View(acs)
View(acs_bbl)
View(acs_bg)
View(bbl_pts)
View(data_list)
gc()
View(rats)
View(rats_enriched)
# Master driver that runs the entire rat‚Äëdata pipeline **in order** and checks
# that every expected artefact is created. Handy for fresh environments or CI.
#
# Outline
# 0. (Optional) setwd() to the repo root.
# 1. Define the ordered vector of R scripts to source.
# 2. Loop through and `source()` each, echoing output.
# 3. Assert that the key CSV / GeoJSON files exist.
# ---------------------------------------------------------------------------
## 0) Working directory -------------------------------------------------------
# Uncomment and edit if you intend to run this outside the project root.
# setwd("C:/path/to/nyc-rat-abundance")
## 1) Scripts to run (ordered) -------------------------------------------------
scripts <- c(
"scripts/000_setup_cmdstanr.R",
"scripts/011_data_prep.R",
"scripts/012_data_prep_derivation.R",  # makes rats_ready + borough_rates
"scripts/021_acs_fetch.R",             # BBL‚Äëkeyed ACS lookup
"scripts/022_spatial_join.R",          # adds PLUTO & ACS to rat points
"scripts/023_income_scatter.R",        # tract‚Äëlevel scatter data
"scripts/024_bg_acs_join.R"            # BG‚Äëlevel join & summary
)
## 2) Run each script, stop on error -----------------------------------------
for (s in scripts) {
message("üîÑ  Running ", s, " ‚Ä¶")
source(s, echo = TRUE)
}
# Master driver that runs the entire rat‚Äëdata pipeline **in order** and checks
# that every expected artefact is created. Handy for fresh environments or CI.
#
# Outline
# 0. (Optional) setwd() to the repo root.
# 1. Define the ordered vector of R scripts to source.
# 2. Loop through and `source()` each, echoing output.
# 3. Assert that the key CSV / GeoJSON files exist.
# ---------------------------------------------------------------------------
## 0) Working directory -------------------------------------------------------
# Uncomment and edit if you intend to run this outside the project root.
# setwd("C:/path/to/nyc-rat-abundance")
## 1) Scripts to run (ordered) -------------------------------------------------
scripts <- c(
"scripts/000_setup_cmdstanr.R",
"scripts/011_data_prep.R",
"scripts/012_data_prep_derivation.R",  # makes rats_ready + borough_rates
"scripts/021_acs_fetch.R",             # BBL‚Äëkeyed ACS lookup
"scripts/022_spatial_join.R",          # adds PLUTO & ACS to rat points
"scripts/023_income_scatter.R",        # tract‚Äëlevel scatter data
"scripts/024_bg_acs_join.R"            # BG‚Äëlevel join & summary
)
## 2) Run each script, stop on error -----------------------------------------
for (s in scripts) {
message("üîÑ  Running ", s, " ‚Ä¶")
source(s, echo = TRUE)
}
## 3) Verify outputs exist -----------------------------------------------------
expected <- c(
"data/processed/rats_ready.csv",
"data/processed/borough_rates.csv",
"data/processed/ACS.csv",
"output/rats_enriched.geojson",
"output/income_scatter.csv",
"output/rat_with_bg_ACS_point.csv",
"output/bg_calls_ACS_summary.csv"
)
missing <- expected[!file.exists(expected)]
if (length(missing) > 0) {
stop("‚ùå  Missing outputs: ", paste(missing, collapse = ", "))
}
message("üéâ  All scripts ran successfully and outputs are in place!")
# Master driver that runs the entire rat‚Äëdata pipeline **in order** and checks
# that every expected artefact is created. Handy for fresh environments or CI.
#
# Outline
# 0. (Optional) setwd() to the repo root.
# 1. Define the ordered vector of R scripts to source.
# 2. Loop through and `source()` each, echoing output.
# 3. Assert that the key CSV / GeoJSON files exist.
# ---------------------------------------------------------------------------
## 0) Working directory -------------------------------------------------------
# Uncomment and edit if you intend to run this outside the project root.
# setwd("C:/path/to/nyc-rat-abundance")
## 1) Scripts to run (ordered) -------------------------------------------------
scripts <- c(
"scripts/000_setup_cmdstanr.R",
"scripts/011_data_prep.R",
"scripts/012_data_prep_derivation.R",  # makes rats_ready + borough_rates
"scripts/021_acs_fetch.R",             # BBL‚Äëkeyed ACS lookup
"scripts/022_spatial_join.R",          # adds PLUTO & ACS to rat points
"scripts/023_income_scatter.R",        # tract‚Äëlevel scatter data
"scripts/024_bg_acs_join.R"            # BG‚Äëlevel join & summary
)
## 2) Run each script, stop on error -----------------------------------------
for (s in scripts) {
message("üîÑ  Running ", s, " ‚Ä¶")
source(s, echo = TRUE)
}
## 3) Verify outputs exist -----------------------------------------------------
expected <- c(
"data/processed/rats_ready.csv",
"data/processed/borough_rates.csv",
"data/processed/ACS.csv",
"output/rats_enriched.geojson",
"output/income_scatter.csv",
"output/rat_with_bg_ACS_point.csv",
"output/bg_calls_ACS_summary.csv"
)
missing <- expected[!file.exists(expected)]
if (length(missing) > 0) {
stop("‚ùå  Missing outputs: ", paste(missing, collapse = ", "))
}
message("üéâ  All scripts ran successfully and outputs are in place!")
# Enrich each cleaned rat sighting with parcel (PLUTO) attributes **and** ACS
# block‚Äëgroup socioeconomic metrics. Result is a ready‚Äëto‚Äëmap GeoJSON.
#
# Workflow
#   1. Read `rats_clean.csv` (already flagged & filtered).
#   2. Convert to an sf points object.
#   3. Spatial‚Äëjoin to MapPLUTO to recover the tax‚Äëlot ID (BBL).
#   4. Bring in full PLUTO attributes and a pre‚Äëbuilt `ACS.csv` keyed by BBL.
#   5. Write one tidy GeoJSON.
#
# Assumes you have already run 021_acs_fetch.R so `ACS.csv` exists.
# -----------------------------------------------------------------------------
## 0) Libraries ----------------------------------------------------------------
library(sf)      # spatial data
library(dplyr)   # %>% and verbs
library(readr)   # read_csv(), write_csv()
## 1) Load cleaned rats data ----------------------------------------------------
rats_clean <- read_csv("data/processed/rats_clean.csv")
## 2) Remove stale BBL col (we‚Äôll re‚Äëattach a fresh one) ------------------------
rats_clean_join <- rats_clean %>% select(-BBL)
# 2b) Drop rows without coordinates ‚Äì can‚Äôt map what we can‚Äôt locate
missing_n <- rats_clean_join %>%
filter(is.na(Longitude) | is.na(Latitude)) %>%
nrow()
if (missing_n > 0) {
message("‚ö†  Dropping ", missing_n, " rows without coordinates")
rats_clean_join <- rats_clean_join %>%
filter(!is.na(Longitude), !is.na(Latitude))
}
## 3) Cast to sf points ---------------------------------------------------------
rat_sf <- st_as_sf(
rats_clean_join,
coords = c("Longitude", "Latitude"),
crs    = 4326,   # WGS84
remove = FALSE
)
## 3b) Read Community District boundaries -------------------------------------
cd_sf <- sf::st_read(
"data/raw/NYC_Community_Districts/NYC_Community_Districts.shp",
quiet = TRUE
) %>%
st_transform(crs = st_crs(rat_sf))
## 3c) Join CD_ID onto each rat point -----------------------------------------
rat_sf <- rat_sf %>%
st_join(
cd_sf %>% select(CD_ID = boro_cd),  # rename the shapefile‚Äôs boro_cd field
join = st_within,
left = TRUE
)
## 4) Read PLUTO parcels & ensure valid geometries -----------------------------
bbl_sf <- st_read("data/raw/MapPLUTO.shp", quiet = TRUE) %>%
st_transform(crs = st_crs(rat_sf))
if (!all(st_is_valid(bbl_sf))) {
message("üîß  Fixing invalid PLUTO polygons ‚Ä¶")
bbl_sf <- st_make_valid(bbl_sf)
}
## 5) Spatial join lots ‚Üí rat points to grab BBL -------------------------------
#    Keep only the BBL column from PLUTO at this stage (lighter memory).
rat_bbl <- st_join(
rat_sf,
bbl_sf %>% select(join_BBL = BBL),
join = st_within,   # point must fall *inside* lot polygon
left = TRUE         # keep all rat points even if no lot (e.g., parks, water)
) %>%
rename(BBL = join_BBL)
## 6) Load full PLUTO attributes (no geometry needed) --------------------------
pluto_attrs <- st_read("data/raw/MapPLUTO.shp", quiet = TRUE) %>%
st_drop_geometry()
## 7) Load ACS metrics keyed by BBL --------------------------------------------
acs <- read_csv("data/processed/ACS.csv")
## 8) Attribute joins -----------------------------------------------------------
rat_enriched <- rat_bbl %>%
left_join(pluto_attrs, by = "BBL") %>%
left_join(acs,         by = "BBL")
## 9) Ensure output dir exists --------------------------------------------------
output_dir <- "output"
if (!dir.exists(output_dir)) dir.create(output_dir, recursive = TRUE)
## 10) Write GeoJSON ------------------------------------------------------------
output_path <- file.path(output_dir, "rats_enriched.geojson")
st_write(rat_enriched, output_path, driver = "GeoJSON", delete_dsn = TRUE)
message("‚úÖ  Spatial join complete ‚Äì wrote " , output_path)
library(sf)
head(sf::st_read("output/rats_enriched.geojson")["CD_ID"])
rats_sf <- sf::st_read("output/rats_enriched.geojson")
summary(rats_sf$CD_ID)          # see the range of districts
sum(is.na(rats_sf$CD_ID))      # should be zero or very small
# 031_qhcr_model.R
# -----------------------------------------------------------------------------
# Build quarterly QHCR (quantitative hierarchical capture‚Äìrecapture) model
# for rat abundance by Community District (CD_ID).
# 1) Read enriched sightings (with CD_ID)
# 2) Assign each sighting to a quarter
# 3) Build capture histories (counts) by CD_ID √ó quarter
# 4) Fit the Stan-based QHCR model
# 5) Export posterior summaries to CSV
# -----------------------------------------------------------------------------
View(rat_sf)
# 031_qhcr_model.R
# -----------------------------------------------------------------------------
# Build quarterly QHCR (quantitative hierarchical capture‚Äìrecapture) model
# for rat abundance by Community District (CD_ID).
# 1) Read enriched sightings (with CD_ID)
# 2) Assign each sighting to a quarter
# 3) Build capture histories (counts) by CD_ID √ó quarter
# 4) Fit the Stan-based QHCR model
# 5) Export posterior summaries to CSV
# -----------------------------------------------------------------------------
# 0) Libraries ---------------------------------------------------------------
library(sf)
library(dplyr)
library(tidyr)
library(lubridate)
library(rstan)
library(posterior)
library(readr)
# 1) Load enriched rat sightings ---------------------------------------------
rats_sf <- sf::st_read(
"output/rats_enriched.geojson",
quiet = TRUE
) %>%
st_drop_geometry()
# 2) Assign each call to a quarter -------------------------------------------
rats_q <- rats_sf %>%
mutate(
call_date = ymd_hms(call_date),
quarter  = floor_date(call_date, unit = "quarter")
) %>%
filter(!is.na(CD_ID))
# 031_qhcr_model.R
# -----------------------------------------------------------------------------
# Build quarterly QHCR (quantitative hierarchical capture‚Äìrecapture) model
# for rat abundance by Community District (CD_ID).
# 1) Read enriched sightings (with CD_ID)
# 2) Assign each sighting to a quarter
# 3) Build capture histories (counts) by CD_ID √ó quarter
# 4) Fit the Stan-based QHCR model
# 5) Export posterior summaries to CSV
# -----------------------------------------------------------------------------
# 0) Libraries ---------------------------------------------------------------
library(sf)
library(dplyr)
library(tidyr)
library(lubridate)
library(rstan)
library(posterior)
library(readr)
# 1) Load enriched rat sightings ---------------------------------------------
rats_sf <- sf::st_read(
"output/rats_enriched.geojson",
quiet = TRUE
) %>%
st_drop_geometry()
# 2) Assign each call to a quarter -------------------------------------------
rats_q <- rats_sf %>%
mutate(
call_date = ymd_hms(call_date),
quarter  = floor_date(call_date, unit = "quarter")
) %>%
filter(!is.na(CD_ID))
View(rat_sf)
# 031_qhcr_model.R
# -----------------------------------------------------------------------------
# Build quarterly QHCR (quantitative hierarchical capture‚Äìrecapture) model
# for rat abundance by Community District (CD_ID).
# 1) Read enriched sightings (with CD_ID)
# 2) Assign each sighting to a quarter
# 3) Build capture histories (counts) by CD_ID √ó quarter
# 4) Fit the Stan-based QHCR model
# 5) Export posterior summaries to CSV
# -----------------------------------------------------------------------------
# 0) Libraries ---------------------------------------------------------------
library(sf)
library(dplyr)
library(tidyr)
library(lubridate)
library(rstan)
library(posterior)
library(readr)
# 1) Load enriched rat sightings ---------------------------------------------
rats_sf <- sf::st_read(
"output/rats_enriched.geojson",
quiet = TRUE
) %>%
st_drop_geometry()
# 2) Assign each call to a quarter -------------------------------------------
# Uses `created_dt` as the timestamp field from rats_enriched.geojson
rats_q <- rats_sf %>%
mutate(
call_date = ymd_hms(created_dt),  # parse the actual date-time field
quarter   = floor_date(call_date, unit = "quarter")
) %>%
filter(!is.na(CD_ID))
# 3) Build capture history matrix --------------------------------------------
# Identify unique districts and occasions
districts <- sort(unique(rats_q$CD_ID))
occasions <- sort(unique(rats_q$quarter))
# Count sightings per district √ó quarter
cap_hist <- rats_q %>%
group_by(CD_ID, quarter) %>%
summarise(calls = n(), .groups = "drop") %>%
complete(
CD_ID   = districts,
quarter = occasions,
fill    = list(calls = 0)
) %>%
arrange(match(CD_ID, districts), quarter) %>%
pivot_wider(
names_from  = quarter,
values_from = calls
)
# Convert to matrix for Stan
count_matrix <- as.matrix(cap_hist[, as.character(occasions)])
# 4) Prepare data list for Stan ----------------------------------------------
stan_data <- list(
D = nrow(count_matrix),     # number of districts
T = ncol(count_matrix),     # number of capture occasions (quarters)
y = count_matrix            # counts matrix
)
# 5) Fit the QHCR model ------------------------------------------------------
# Ensure you have a Stan model at `stan/qhcr_model.stan`
stan_model <- rstan::stan_model("stan/qhcr_model.stan")
file.exists("stan/qhcr_model.stan")
file.exists("stan/qhcr_model.stan")
list.files("stan")
file.rename(
from = "stan/qhcr_model.stan.txt",
to   = "stan/qhcr_model.stan"
)
file.exists("stan/qhcr_model.stan")
View(rat_sf)
# 031_qhcr_model.R
# -----------------------------------------------------------------------------
# Build quarterly QHCR (quantitative hierarchical capture‚Äìrecapture) model
# for rat abundance by Community District (CD_ID).
# 1) Read enriched sightings (with CD_ID)
# 2) Assign each sighting to a quarter
# 3) Build capture histories (counts) by CD_ID √ó quarter
# 4) Fit the Stan-based QHCR model
# 5) Export posterior summaries to CSV
# -----------------------------------------------------------------------------
# 0) Libraries ---------------------------------------------------------------
library(sf)
library(dplyr)
library(tidyr)
library(lubridate)
library(rstan)
library(posterior)
library(readr)
# 1) Load enriched rat sightings ---------------------------------------------
rats_sf <- sf::st_read(
"output/rats_enriched.geojson",
quiet = TRUE
) %>%
st_drop_geometry()
# 2) Assign each sighting to a quarter ---------------------------------------
# Uses `created_dt` as the timestamp field
rats_q <- rats_sf %>%
mutate(
call_date = ymd_hms(created_dt),  # parse the actual date-time field
quarter   = floor_date(call_date, unit = "quarter")
) %>%
filter(!is.na(CD_ID))
# 3) Build capture history matrix --------------------------------------------
districts <- sort(unique(rats_q$CD_ID))
occasions <- sort(unique(rats_q$quarter))
cap_hist <- rats_q %>%
group_by(CD_ID, quarter) %>%
summarise(calls = n(), .groups = "drop") %>%
complete(
CD_ID   = districts,
quarter = occasions,
fill    = list(calls = 0)
) %>%
arrange(match(CD_ID, districts), quarter) %>%
pivot_wider(
names_from  = quarter,
values_from = calls
)
# Convert to matrix for Stan
count_matrix <- as.matrix(cap_hist[, as.character(occasions)])
# 4) Prepare data list for Stan ----------------------------------------------
stan_data <- list(
D = nrow(count_matrix),     # number of districts
T = ncol(count_matrix),     # number of capture occasions (quarters)
y = count_matrix            # counts matrix
)
# 5) Fit the QHCR model ------------------------------------------------------
stan_model <- rstan::stan_model("stan/qhcr_model.stan")
# 031_qhcr_model.R
# -----------------------------------------------------------------------------
# Build quarterly QHCR (quantitative hierarchical capture‚Äìrecapture) model
# for rat abundance by Community District (CD_ID).
# 1) Read enriched sightings (with CD_ID)
# 2) Assign each sighting to a quarter
# 3) Build capture histories (counts) by CD_ID √ó quarter
# 4) Fit the Stan-based QHCR model
# 5) Export posterior summaries to CSV
# -----------------------------------------------------------------------------
# 0) Libraries ---------------------------------------------------------------
library(sf)
library(dplyr)
library(tidyr)
library(lubridate)
library(rstan)
library(posterior)
library(readr)
# 1) Load enriched rat sightings ---------------------------------------------
rats_sf <- sf::st_read(
"output/rats_enriched.geojson",
quiet = TRUE
) %>%
st_drop_geometry()
# 2) Assign each sighting to a quarter ---------------------------------------
# Uses `created_dt` as the timestamp field
rats_q <- rats_sf %>%
mutate(
call_date = ymd_hms(created_dt),  # parse the actual date-time field
quarter   = floor_date(call_date, unit = "quarter")
) %>%
filter(!is.na(CD_ID))
# 3) Build capture history matrix --------------------------------------------
districts <- sort(unique(rats_q$CD_ID))
occasions <- sort(unique(rats_q$quarter))
cap_hist <- rats_q %>%
group_by(CD_ID, quarter) %>%
summarise(calls = n(), .groups = "drop") %>%
complete(
CD_ID   = districts,
quarter = occasions,
fill    = list(calls = 0)
) %>%
arrange(match(CD_ID, districts), quarter) %>%
pivot_wider(
names_from  = quarter,
values_from = calls
)
# Convert to matrix for Stan
count_matrix <- as.matrix(cap_hist[, as.character(occasions)])
# 4) Prepare data list for Stan ----------------------------------------------
stan_data <- list(
D = nrow(count_matrix),     # number of districts
T = ncol(count_matrix),     # number of capture occasions (quarters)
y = count_matrix            # counts matrix
)
# 5) Fit the QHCR model ------------------------------------------------------
stan_model <- rstan::stan_model("stan/qhcr_model.stan")
