rate_per_10k_y_tr = rate_per_10k_y),
by = "tract_id"
) %>%
mutate(
income_decile   = coalesce(income_decile,   income_decile_tr),
rate_per_10k_y  = coalesce(rate_per_10k_y,  rate_per_10k_y_tr)
) %>%
select(-income_decile_tr, -rate_per_10k_y_tr)
cat("🔍 Unmatched after fallback:",
sum(is.na(rats_joined$income_decile)), "records\n")
# ---------- 5.  Quarter field ---------------------------------------------- #
rats_joined <- rats_joined %>%
mutate(
created_dt = ymd_hms(created_dt),
quarter    = paste0(year(created_dt), "-Q", quarter(created_dt))
)
# ---------- 6.  Quarterly counts per decile -------------------------------- #
quarterly <- rats_joined %>%
group_by(income_decile, quarter) %>%
summarise(calls = n(), .groups = "drop")
decile_counts <- quarterly %>%
group_by(income_decile) %>%
summarise(
avg_calls_per_quarter = mean(calls),
total_calls           = sum(calls),
.groups = "drop"
)
write_csv(decile_counts, "output/decile_call_counts_final.csv")
# ---------- 7.  Median per-YEAR rate per decile ---------------------------- #
decile_rates <- bg %>%
group_by(income_decile) %>%
summarise(
median_rate_per_year = median(rate_per_10k_y, na.rm = TRUE),
.groups = "drop"
)
write_csv(decile_rates, "output/decile_call_rates_final.csv")
message("✅  output/decile_call_counts_final.csv")
message("✅  output/decile_call_rates_final.csv")
View(decile_counts)
View(decile_rates)
library(sf)
library(dplyr)
library(readr)
library(lubridate)
library(stringr)
# ---------- 1.  Load data --------------------------------------------------- #
rats <- st_read("output/rats_enriched.geojson", quiet = TRUE) %>% st_drop_geometry()
bg   <- read_csv("output/bg_calls_ACS_summary.csv", show_col_types = FALSE)
# ---------- 2.  Harmonise keys --------------------------------------------- #
rats <- rats %>%
mutate(
GEOID      = str_pad(as.character(GEOID), 12, pad = "0"),
tract_id   = str_sub(GEOID, 1, 11)                     # first 11 digits
)
bg   <- bg %>%
mutate(
GEOID      = str_pad(as.character(GEOID), 12, pad = "0"),
tract_id   = str_sub(GEOID, 1, 11)
)
# ---------- 3.  Build income deciles --------------------------------------- #
bg <- bg %>%
mutate(income_decile = ntile(med_income, 10))
#   Derive rate PER-YEAR per 10 k pop  (calls over 15 yrs ➟ ÷ 15)
n_years <- length(unique(year(rats$created_dt)))            # usually 15
bg <- bg %>%
mutate(rate_per_10k_y = (calls / n_years) / (pop_tot / 1e4))
# ---------- 4.  Attach decile & rate to each sighting ---------------------- #
#    a) First try exact BG match
rats_joined <- rats %>%
left_join(bg %>% select(GEOID, income_decile, rate_per_10k_y),
by = "GEOID")
#    b) Where still missing, fall back to tract match
rats_joined <- rats_joined %>%
left_join(
bg %>% select(tract_id, income_decile_tr = income_decile,
rate_per_10k_y_tr = rate_per_10k_y),
by = "tract_id"
) %>%
mutate(
income_decile   = coalesce(income_decile,   income_decile_tr),
rate_per_10k_y  = coalesce(rate_per_10k_y,  rate_per_10k_y_tr)
) %>%
select(-income_decile_tr, -rate_per_10k_y_tr)
cat("🔍 Unmatched after fallback:",
sum(is.na(rats_joined$income_decile)), "records\n")
# ---------- 5.  Quarter field ---------------------------------------------- #
rats_joined <- rats_joined %>%
mutate(
created_dt = ymd_hms(created_dt),
quarter    = paste0(year(created_dt), "-Q", quarter(created_dt))
)
# ---------- 6.  Quarterly counts per decile -------------------------------- #
quarterly <- rats_joined %>%
group_by(income_decile, quarter) %>%
summarise(calls = n(), .groups = "drop")
decile_counts <- quarterly %>%
group_by(income_decile) %>%
summarise(
avg_calls_per_quarter = mean(calls),
total_calls           = sum(calls),
.groups = "drop"
)
write_csv(decile_counts, "output/decile_call_counts_final.csv")
# ---------- 7.  Median per-YEAR rate per decile ---------------------------- #
decile_rates <- bg %>%
group_by(income_decile) %>%
summarise(
median_rate_per_year = median(rate_per_10k_y, na.rm = TRUE),
.groups = "drop"
)
write_csv(decile_rates, "output/decile_call_rates_final.csv")
message("✅  output/decile_call_counts_final.csv")
message("✅  output/decile_call_rates_final.csv")
View(quarterly)
View(decile_counts)
View(decile_rates)
table(nchar(rats$GEOID), useNA = "ifany")
View(rats)
View(rats)
library(sf)
library(dplyr)
library(readr)
library(lubridate)
library(stringr)
#— 1. Load your enriched points ——
rats <- st_read("output/rats_enriched.geojson", quiet = TRUE) %>%
st_drop_geometry()
#— 2. Derive 12-digit block_group ID from CB2010 ——
rats <- rats %>%
mutate(
CB2010 = as.character(CB2010),
block_group = str_sub(str_pad(CB2010, 12, pad = "0"), 1, 12)
)
#— 3. Parse datetime → quarter ——
rats <- rats %>%
mutate(
created_dt = ymd_hms(created_dt),
quarter    = paste0(year(created_dt), "-Q", quarter(created_dt))
)
#— 4. Load ACS block-group summary & build deciles + per-year rate ——
bg <- read_csv("output/bg_calls_ACS_summary.csv", show_col_types = FALSE) %>%
rename(block_group = GEOID) %>%
mutate(
# how many years in your data? (usually 15: 2010–2024)
n_years = length(unique(year(rats$created_dt))),
income_decile  = ntile(med_income, 10),
rate_per_10k_y = (calls / n_years) / (pop_tot / 1e4)
) %>%
select(block_group, income_decile, rate_per_10k_y)
#— 5. Join decile & rate back onto each sighting ——
rats2 <- rats %>%
left_join(bg, by = "block_group") %>%
# any still-missing → “11” (Unknown)
mutate(income_decile = coalesce(income_decile, 11))
#— 2. Derive 12-digit block_group ID from CB2010 ——
rats <- rats %>%
mutate(
CB2010 = as.character(CB2010),
block_group = str_sub(str_pad(CB2010, 12, pad = "0"), 1, 12)
)
#— 3. Parse datetime → quarter ——
rats <- rats %>%
mutate(
created_dt = ymd_hms(created_dt),
quarter    = paste0(year(created_dt), "-Q", quarter(created_dt))
)
#— 4. Load ACS block-group summary & build deciles + per-year rate ——
bg <- read_csv("output/bg_calls_ACS_summary.csv", show_col_types = FALSE) %>%
rename(block_group = GEOID) %>%
mutate(
# how many years in your data? (usually 15: 2010–2024)
n_years = length(unique(year(rats$created_dt))),
income_decile  = ntile(med_income, 10),
rate_per_10k_y = (calls / n_years) / (pop_tot / 1e4)
) %>%
select(block_group, income_decile, rate_per_10k_y)
rats <- rats %>%
mutate(block_group = as.character(block_group))
bg <- bg %>%
mutate(block_group = as.character(block_group))
#— 5. Join decile & rate back onto each sighting ——
rats2 <- rats %>%
left_join(bg, by = "block_group") %>%
# any still-missing → “11” (Unknown)
mutate(income_decile = coalesce(income_decile, 11))
# sanity check: should be tiny
cat("Unmatched (decile=11):", sum(rats2$income_decile==11), "of", nrow(rats2), "\n")
#— 6. Quarterly counts per decile ——
quarterly <- rats2 %>%
group_by(income_decile, quarter) %>%
summarise(calls = n(), .groups = "drop")
decile_counts <- quarterly %>%
group_by(income_decile) %>%
summarise(
avg_calls_per_quarter = mean(calls),
total_calls           = sum(calls),
.groups               = "drop"
)
write_csv(decile_counts, "output/decile_call_counts_final3.csv")
#— 7. Median per-YEAR rate per decile ——
decile_rates <- bg %>%
group_by(income_decile) %>%
summarise(
median_rate_per_year = median(rate_per_10k_y, na.rm = TRUE),
.groups = "drop"
)
write_csv(decile_rates, "output/decile_call_rates_final3.csv")
message("✅ Written final3 CSVs to output/")
View(decile_rates)
View(decile_counts)
library(sf); library(dplyr); library(readr); library(lubridate)
# 1. Load your enriched points
rats_geo <- st_read("output/rats_enriched.geojson", quiet=TRUE) %>%
st_drop_geometry()
# 2. Load ACS block‐group summary (for pop_tot)
bg       <- read_csv("output/bg_calls_ACS_summary.csv", show_col_types=FALSE)
# 3. Parse date → quarter
rats_q <- rats_geo %>%
mutate(
created_dt = ymd_hms(created_dt),
quarter    = paste0(year(created_dt), "-Q", quarter(created_dt))
)
# 4. Count calls per BG × quarter
quarterly_bg <- rats_q %>%
group_by(GEOID, quarter) %>%
summarise(calls = n(), .groups="drop") %>%
# join in population
left_join(bg %>% select(GEOID, pop_tot), by="GEOID") %>%
# compute rate per 10 k
mutate(rate_per_10k_q = calls / (pop_tot/1e4))
# 5. Compute the median
median_rate <- median(quarterly_bg$rate_per_10k_q, na.rm=TRUE)
print(median_rate)
# 2. Get total city population (sum of all block-groups)
bg   <- read_csv("output/bg_calls_ACS_summary.csv", show_col_types=FALSE)
city_pop_10k <- sum(bg$pop_tot) / 1e4
# 3. Compute calls & rate per quarter
city_q <- rats %>%
group_by(quarter) %>%
summarise(calls = n(), .groups="drop") %>%
mutate(rate_per_10k = calls / city_pop_10k)
# 4. Median (and mean) across the 58 quarters
median_rate <- median(city_q$rate_per_10k)
mean_rate   <- mean(city_q$rate_per_10k)
print(median_rate)  # should be ~200 ± 15 %
print(mean_rate)    # will be similar
library(dplyr)
library(readr)
library(lubridate)
# 1. Load 311 points & parse quarters
rats <- read_csv("output/rats_enriched.csv") %>%
mutate(
created_dt = ymd_hms(created_dt),
quarter    = paste0(year(created_dt), "-Q", quarter(created_dt))
)
library(sf)
library(dplyr)
library(readr)
library(lubridate)
# 1. Load enriched GeoJSON and drop geometry
rats_geo <- st_read("output/rats_enriched.geojson", quiet = TRUE) %>%
st_drop_geometry()
# 2. Parse created_dt → quarter
rats_q <- rats_geo %>%
mutate(
created_dt = ymd_hms(created_dt),
quarter    = paste0(year(created_dt), "-Q", quarter(created_dt))
)
# 3. Load ACS block-group summary for total population
bg <- read_csv("output/bg_calls_ACS_summary.csv", show_col_types = FALSE)
# compute city population in 10k units
city_pop_10k <- sum(bg$pop_tot, na.rm = TRUE) / 1e4
# 4. Aggregate calls per quarter and compute rate per 10k
city_q <- rats_q %>%
group_by(quarter) %>%
summarise(calls = n(), .groups = "drop") %>%
mutate(rate_per_10k = calls / city_pop_10k)
# 5. Compute median & mean across all quarters
median_rate <- median(city_q$rate_per_10k, na.rm = TRUE)
mean_rate   <- mean(city_q$rate_per_10k, na.rm = TRUE)
print(glue::glue("Median calls per 10k per quarter: {round(median_rate,1)}"))
print(glue::glue("Mean   calls per 10k per quarter: {round(mean_rate,1)}"))
library(sf)
library(dplyr)
library(readr)
library(lubridate)
# 1. Load your enriched sightings and ACS BG summary
rats_geo <- st_read("output/rats_enriched.geojson", quiet = TRUE) %>%
st_drop_geometry() %>%
mutate(GEOID = as.character(GEOID))
bg <- read_csv("output/bg_calls_ACS_summary.csv", show_col_types = FALSE) %>%
mutate(GEOID = as.character(GEOID))
# 2. Build a lookup of population by decile
bg_deciles <- bg %>%
mutate(income_decile = ntile(med_income, 10)) %>%
group_by(income_decile) %>%
summarise(
decile_pop = sum(pop_tot, na.rm = TRUE),
.groups = "drop"
)
# 3. Attach decile to each sighting
rats2 <- rats_geo %>%
left_join(
bg %>% select(GEOID, med_income) %>%
mutate(income_decile = ntile(med_income,10)),
by = "GEOID"
)
# 4. Derive quarters
rats2 <- rats2 %>%
mutate(
created_dt = ymd_hms(created_dt),
quarter    = paste0(year(created_dt), "-Q", quarter(created_dt))
)
# 5. Count calls per decile × quarter
calls_q <- rats2 %>%
group_by(income_decile, quarter) %>%
summarise(calls = n(), .groups = "drop")
# 6. Bring in decile population
calls_q <- calls_q %>%
left_join(bg_deciles, by = "income_decile")
# 7. Compute per-quarter rate per 10 k for each decile
rates_q <- calls_q %>%
mutate(rate_per_10k = calls / (decile_pop / 1e4))
# 8. Summarise across quarters
decile_rate_summary <- rates_q %>%
group_by(income_decile) %>%
summarise(
median_rate_q = median(rate_per_10k, na.rm=TRUE),
mean_rate_q   = mean(rate_per_10k, na.rm=TRUE),
.groups = "drop"
)
print(decile_rate_summary)
#!/usr/bin/env Rscript
# 033_decile_rates_from_bg.R
# ————————————————————————————————
# Reads the block-group summary → recalculates decile-based median call-rates
# Outputs: output/decile_call_rates_bg.csv
# ————————————————————————————————
library(dplyr)
library(readr)
# 1. Load your block-group ACS summary (must include rate_per_10k & med_income)
bg <- read_csv("output/bg_calls_ACS_summary.csv", show_col_types = FALSE)
# 2. Assign each BG to an income decile based on median household income
bg_deciles <- bg %>%
filter(!is.na(med_income)) %>%
mutate(income_decile = ntile(med_income, 10))
# 3. Compute the median BG call-rate per quarter per 10k within each decile
decile_rates_bg <- bg_deciles %>%
group_by(income_decile) %>%
summarise(
median_rate_per_qtr = median(rate_per_10k, na.rm = TRUE),
.groups = "drop"
)
# 4. Write out your new decile rates CSV
write_csv(decile_rates_bg, "output/decile_call_rates_bg.csv")
message("✅ Written output/decile_call_rates_bg.csv — ready for Tableau.")
#!/usr/bin/env Rscript
# 033_decile_rates_from_bg.R
# ————————————————————————————————
# Reads the block-group summary → recalculates decile-based median call-rates
# Outputs: output/decile_call_rates_bg.csv
# ————————————————————————————————
library(dplyr)
library(readr)
# 1. Load your block-group ACS summary (must include rate_per_10k & med_income)
bg <- read_csv("output/bg_calls_ACS_summary.csv", show_col_types = FALSE)
# 2. Assign each BG to an income decile based on median household income
bg_deciles <- bg %>%
filter(!is.na(med_income)) %>%
mutate(income_decile = ntile(med_income, 10))
# 3. Compute the median BG call-rate per quarter per 10k within each decile
decile_rates_bg <- bg_deciles %>%
group_by(income_decile) %>%
summarise(
median_rate_per_qtr = median(rate_per_10k, na.rm = TRUE),
.groups = "drop"
)
# 4. Write out your new decile rates CSV
write_csv(decile_rates_bg, "output/decile_call_rates_bg.csv")
message("✅ Written output/decile_call_rates_bg.csv — ready for Tableau.")
View(decile_rates_bg)
library(sf)       # for st_read
library(dplyr)
library(readr)
library(lubridate)
# ---------- 0.  Paths -------------------
rats_path <- "output/rats_enriched.geojson"
bg_path   <- "output/bg_calls_ACS_summary.csv"
out_dir   <- "output"
# ---------- 1.  Load block-group ACS summary -------------------
bg <- read_csv(bg_path, show_col_types = FALSE) |>
mutate(
GEOID         = as.character(GEOID),
income_decile = ntile(med_income, 10)      # decile on median income
)
# ---------- 2.  DECILE median rate (calls / qtr / 10k) ----------
decile_rates <- bg |>
group_by(income_decile) |>
summarise(
median_rate_per_qtr = median(rate_per_10k, na.rm = TRUE),
.groups = "drop"
)
write_csv(decile_rates,
file.path(out_dir, "decile_call_rates_vfinal.csv"))
# ---------- 3.  CITY-WIDE rate for reference -------------------
# 3a. Parse quarters for all 311 sightings
rats <- st_read(rats_path, quiet = TRUE) |>
st_drop_geometry() |>
mutate(
created_dt = ymd_hms(created_dt),
quarter    = paste0(year(created_dt), "-Q", quarter(created_dt))
)
# 3b. Total population (all BGs)
city_pop_10k <- sum(bg$pop_tot, na.rm = TRUE) / 1e4
# 3c. Calls per quarter, then rate
city_qtr <- rats |>
group_by(quarter) |>
summarise(calls = n(), .groups = "drop") |>
mutate(rate_per_10k = calls / city_pop_10k)
city_stats <- summarise(city_qtr,
median_rate_per_qtr = median(rate_per_10k),
mean_rate_per_qtr   = mean(rate_per_10k))
write_csv(city_stats,
file.path(out_dir, "citywide_call_rate_qtr.csv"))
message("✅  Wrote:")
message("   • ", file.path(out_dir, "decile_call_rates_vfinal.csv"))
message("   • ", file.path(out_dir, "citywide_call_rate_qtr.csv"))
View(city_stats)
View(city_qtr)
View(decile_rates)
View(decile_rates_bg)
View(decile_rates)
View(decile_rates_bg)
print(decile_rates)
print(city_stats)
library(sf)
library(dplyr)
library(readr)
library(lubridate)
# ——— Paths ——————————————————————————————————————————————
rats_path <- "output/rats_enriched.geojson"
bg_path   <- "output/bg_calls_ACS_summary.csv"
out_dir   <- "output"
# Number of quarters in your span (2010 to May 2025 ≈ 58 qtrs)
n_quarters <- 58
# ——— 1. Load and prep BG summary ————————————————————————
bg <- read_csv(bg_path, show_col_types = FALSE) %>%
mutate(
GEOID         = as.character(GEOID),
income_decile = ntile(med_income, 10),
# Convert TOTAL‐PERIOD rate to PER-QUARTER
rate_per_qtr_per_10k = rate_per_10k / n_quarters
) %>%
select(GEOID, income_decile, rate_per_qtr_per_10k, pop_tot)
# ——— 2. Compute decile median rates ——————————————————————
decile_rates <- bg %>%
group_by(income_decile) %>%
summarise(
median_rate_per_qtr = median(rate_per_qtr_per_10k, na.rm = TRUE),
.groups = "drop"
)
# Write decile CSV
decile_csv <- file.path(out_dir, "decile_call_rates_vfinal.csv")
write_csv(decile_rates, decile_csv)
# ——— 3. Load enriched sightings & derive quarters ————————————
rats <- st_read(rats_path, quiet = TRUE) %>%
st_drop_geometry() %>%
mutate(
created_dt = ymd_hms(created_dt),
quarter    = paste0(year(created_dt), "-Q", quarter(created_dt))
)
# ——— 4. Compute citywide per-quarter rates ——————————————————
# Total city pop in 10k units
city_pop_10k <- sum(bg$pop_tot, na.rm = TRUE) / 1e4
city_qtr <- rats %>%
group_by(quarter) %>%
summarise(calls = n(), .groups = "drop") %>%
mutate(rate_per_10k = calls / city_pop_10k)
city_stats <- city_qtr %>%
summarise(
median_rate_per_qtr = median(rate_per_10k, na.rm = TRUE),
mean_rate_per_qtr   = mean(rate_per_10k,   na.rm = TRUE),
.groups = "drop"
)
# Write citywide CSV
city_csv <- file.path(out_dir, "citywide_call_rate_qtr.csv")
write_csv(city_stats, city_csv)
# ——— 5. Console output ——————————————————————————————
message("✅ Wrote decile rates to: ", decile_csv)
print(decile_rates)
message("\n✅ Wrote citywide rates to: ", city_csv)
print(city_stats)
install.packages(c("vroom", "dplyr", "stringr", "lubridate", "readr", "rstudioapi"))
library(vroom)      # Fast CSV reader (multi-threaded)
library(dplyr)      # Data wrangling verbs (filter/ mutate / summarise …)
library(stringr)    # Regex helpers that read like English
library(lubridate)  # Date-time parsing without tears
library(readr)      # write_csv() for output
install.packages(c("vroom", "dplyr", "stringr", "lubridate", "readr", "rstudioapi"))
# load your clean, enriched sightings
rats <- read_csv("output/rats_enriched.geojson") %>%
mutate(
created_dt = ymd_hms(created_dt),
quarter    = paste0(year(created_dt), "-Q", quarter(created_dt))
)
head(output/rats_enriched.geojson)
# load your clean, enriched sightings
rats <- read_csv("output/rats_enriched.geojson") %>%
mutate(
created_dt = ymd_hms(Created),
quarter    = paste0(year(), "-Q", quarter(Created))
)
