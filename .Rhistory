y = count_matrix            # counts matrix
)
# 5) Fit the QHCR model ------------------------------------------------------
stan_model <- rstan::stan_model("stan/qhcr_model.stan")
file.edit("~/.Renviron")
# Master driver that runs the entire rat‚Äëdata pipeline **in order** and checks
# that every expected artefact is created. Handy for fresh environments or CI.
#
# Outline
# 0. (Optional) setwd() to the repo root.
# 1. Define the ordered vector of R scripts to source.
# 2. Loop through and `source()` each, echoing output.
# 3. Assert that the key CSV / GeoJSON files exist.
# ---------------------------------------------------------------------------
## 0) Working directory -------------------------------------------------------
# Uncomment and edit if you intend to run this outside the project root.
# setwd("C:/path/to/nyc-rat-abundance")
## 1) Scripts to run (ordered) -------------------------------------------------
scripts <- c(
"scripts/000_setup_cmdstanr.R",
"scripts/011_data_prep.R",
"scripts/012_data_prep_derivation.R",  # makes rats_ready + borough_rates
"scripts/021_acs_fetch.R",             # BBL‚Äëkeyed ACS lookup
"scripts/022_spatial_join.R",          # adds PLUTO & ACS to rat points
"scripts/023_income_scatter.R",        # tract‚Äëlevel scatter data
"scripts/024_bg_acs_join.R"            # BG‚Äëlevel join & summary
)
## 2) Run each script, stop on error -----------------------------------------
for (s in scripts) {
message("üîÑ  Running ", s, " ‚Ä¶")
source(s, echo = TRUE)
}
file.edit("~/.Renviron")
Sys.getenv("PATH")
Sys.which("g++")
pkgbuild::has_build_tools()
pkgbuild::has_build_tools()
pkgbuild::has_build_tools(debug = TRUE)
pkgbuild::has_build_tools(debug = TRUE)
gc()
# Master driver that runs the entire rat‚Äëdata pipeline **in order** and checks
# that every expected artefact is created. Handy for fresh environments or CI.
#
# Outline
# 0. (Optional) setwd() to the repo root.
# 1. Define the ordered vector of R scripts to source.
# 2. Loop through and `source()` each, echoing output.
# 3. Assert that the key CSV / GeoJSON files exist.
# ---------------------------------------------------------------------------
## 0) Working directory -------------------------------------------------------
# Uncomment and edit if you intend to run this outside the project root.
# setwd("C:/path/to/nyc-rat-abundance")
## 1) Scripts to run (ordered) -------------------------------------------------
scripts <- c(
"scripts/000_setup_cmdstanr.R",
"scripts/011_data_prep.R",
"scripts/012_data_prep_derivation.R",  # makes rats_ready + borough_rates
"scripts/021_acs_fetch.R",             # BBL‚Äëkeyed ACS lookup
"scripts/022_spatial_join.R",          # adds PLUTO & ACS to rat points
"scripts/023_income_scatter.R",        # tract‚Äëlevel scatter data
"scripts/024_bg_acs_join.R"            # BG‚Äëlevel join & summary
)
## 2) Run each script, stop on error -----------------------------------------
for (s in scripts) {
message("üîÑ  Running ", s, " ‚Ä¶")
source(s, echo = TRUE)
}
# Master driver that runs the entire rat‚Äëdata pipeline **in order** and checks
# that every expected artefact is created. Handy for fresh environments or CI.
#
# Outline
# 0. (Optional) setwd() to the repo root.
# 1. Define the ordered vector of R scripts to source.
# 2. Loop through and `source()` each, echoing output.
# 3. Assert that the key CSV / GeoJSON files exist.
# ---------------------------------------------------------------------------
## 0) Working directory -------------------------------------------------------
# Uncomment and edit if you intend to run this outside the project root.
# setwd("C:/path/to/nyc-rat-abundance")
## 1) Scripts to run (ordered) -------------------------------------------------
scripts <- c(
"scripts/000_setup_cmdstanr.R",
"scripts/011_data_prep.R",
"scripts/012_data_prep_derivation.R",  # makes rats_ready + borough_rates
"scripts/021_acs_fetch.R",             # BBL‚Äëkeyed ACS lookup
"scripts/022_spatial_join.R",          # adds PLUTO & ACS to rat points
"scripts/023_income_scatter.R",        # tract‚Äëlevel scatter data
"scripts/024_bg_acs_join.R"            # BG‚Äëlevel join & summary
)
## 2) Run each script, stop on error -----------------------------------------
for (s in scripts) {
message("üîÑ  Running ", s, " ‚Ä¶")
source(s, echo = TRUE)
}
## 3) Verify outputs exist -----------------------------------------------------
expected <- c(
"data/processed/rats_ready.csv",
"data/processed/borough_rates.csv",
"data/processed/ACS.csv",
"output/rats_enriched.geojson",
"output/income_scatter.csv",
"output/rat_with_bg_ACS_point.csv",
"output/bg_calls_ACS_summary.csv"
)
missing <- expected[!file.exists(expected)]
if (length(missing) > 0) {
stop("‚ùå  Missing outputs: ", paste(missing, collapse = ", "))
}
message("üéâ  All scripts ran successfully and outputs are in place!")
# 031_qhcr_model.R
# -----------------------------------------------------------------------------
# Build quarterly QHCR (quantitative hierarchical capture‚Äìrecapture) model
# for rat abundance by Community District (CD_ID).
# 1) Read enriched sightings (with CD_ID)
# 2) Assign each sighting to a quarter
# 3) Build capture histories (counts) by CD_ID √ó quarter
# 4) Fit the Stan-based QHCR model
# 5) Export posterior summaries to CSV
# -----------------------------------------------------------------------------
# 0) Libraries ---------------------------------------------------------------
library(sf)
library(dplyr)
library(tidyr)
library(lubridate)
library(rstan)
library(posterior)
library(readr)
# 1) Load enriched rat sightings ---------------------------------------------
rats_sf <- sf::st_read(
"output/rats_enriched.geojson",
quiet = TRUE
) %>%
st_drop_geometry()
# 2) Assign each sighting to a quarter ---------------------------------------
# Uses `created_dt` as the timestamp field
rats_q <- rats_sf %>%
mutate(
call_date = ymd_hms(created_dt),  # parse the actual date-time field
quarter   = floor_date(call_date, unit = "quarter")
) %>%
filter(!is.na(CD_ID))
# 3) Build capture history matrix --------------------------------------------
districts <- sort(unique(rats_q$CD_ID))
occasions <- sort(unique(rats_q$quarter))
cap_hist <- rats_q %>%
group_by(CD_ID, quarter) %>%
summarise(calls = n(), .groups = "drop") %>%
complete(
CD_ID   = districts,
quarter = occasions,
fill    = list(calls = 0)
) %>%
arrange(match(CD_ID, districts), quarter) %>%
pivot_wider(
names_from  = quarter,
values_from = calls
)
# Convert to matrix for Stan
count_matrix <- as.matrix(cap_hist[, as.character(occasions)])
# 4) Prepare data list for Stan ----------------------------------------------
stan_data <- list(
D = nrow(count_matrix),     # number of districts
T = ncol(count_matrix),     # number of capture occasions (quarters)
y = count_matrix            # counts matrix
)
# 5) Fit the QHCR model ------------------------------------------------------
stan_model <- rstan::stan_model("stan/qhcr_model.stan")
fit <- rstan::sampling(
object = stan_model,
data   = stan_data,
iter   = 2000,
chains = 4,
cores  = parallel::detectCores()
)
# 031_qhcr_model.R
# -----------------------------------------------------------------------------
# Build quarterly QHCR (quantitative hierarchical capture‚Äìrecapture) model
# for rat abundance by Community District (CD_ID).
# 1) Read enriched sightings (with CD_ID)
# 2) Assign each sighting to a quarter
# 3) Build capture histories (counts) by CD_ID √ó quarter
# 4) Fit the Stan-based QHCR model
# 5) Export posterior summaries to CSV
# -----------------------------------------------------------------------------
install.packages("rstudioapi")
# 0) Libraries ---------------------------------------------------------------
library(sf)
library(dplyr)
library(tidyr)
library(lubridate)
library(rstan)
library(posterior)
library(readr)
# 1) Load enriched rat sightings ---------------------------------------------
rats_sf <- sf::st_read(
"output/rats_enriched.geojson",
quiet = TRUE
) %>%
st_drop_geometry()
# 2) Assign each sighting to a quarter ---------------------------------------
# Uses `created_dt` as the timestamp field
rats_q <- rats_sf %>%
mutate(
call_date = ymd_hms(created_dt),  # parse the actual date-time field
quarter   = floor_date(call_date, unit = "quarter")
) %>%
filter(!is.na(CD_ID))
# 3) Build capture history matrix --------------------------------------------
districts <- sort(unique(rats_q$CD_ID))
occasions <- sort(unique(rats_q$quarter))
cap_hist <- rats_q %>%
group_by(CD_ID, quarter) %>%
summarise(calls = n(), .groups = "drop") %>%
complete(
CD_ID   = districts,
quarter = occasions,
fill    = list(calls = 0)
) %>%
arrange(match(CD_ID, districts), quarter) %>%
pivot_wider(
names_from  = quarter,
values_from = calls
)
# Convert to matrix for Stan
count_matrix <- as.matrix(cap_hist[, as.character(occasions)])
# 4) Prepare data list for Stan ----------------------------------------------
stan_data <- list(
D = nrow(count_matrix),     # number of districts
T = ncol(count_matrix),     # number of capture occasions (quarters)
y = count_matrix            # counts matrix
)
# 5) Fit the QHCR model ------------------------------------------------------
stan_model <- rstan::stan_model("stan/qhcr_model.stan")
fit <- rstan::sampling(
object = stan_model,
data   = stan_data,
iter   = 2000,
chains = 4,
cores  = parallel::detectCores()
)
# 6) Extract posterior summaries ---------------------------------------------
post <- as_draws_df(fit)
lambda_summ <- post %>%
select(starts_with("lambda[")) %>%
summarise_draws(
mean,
~quantile(.x, c(0.025, 0.975))
) %>%
rename(
estimate = mean,
lower    = `2.5%`,
upper    = `97.5%`
) %>%
mutate(
CD_ID = as.integer(str_extract(variable, "\\d+(?=\\])"))
) %>%
select(CD_ID, estimate, lower, upper)
# 7) Export to CSV -----------------------------------------------------------
write_csv(
lambda_summ,
file = "output/district_qhcr.csv"
)
message("‚úÖ QHCR model complete ‚Äì wrote output/district_qhcr.csv")
readr::read_csv("output/district_qhcr.csv") %>% head()
# 031_qhcr_model.R
# -----------------------------------------------------------------------------
# Build quarterly QHCR model for rat abundance by Community District (CD_ID)
# Steps:
# 1) Read enriched sightings (with CD_ID)
# 2) Assign each sighting to a quarter
# 3) Build capture histories (counts) by CD_ID √ó quarter
# 4) Fit Stan-based QHCR model
# 5) Export posterior summaries to CSV (with correct CD_ID mapping)
# -----------------------------------------------------------------------------
# 0) Libraries
library(sf)
library(dplyr)
library(tidyr)
library(lubridate)
library(rstan)
library(posterior)
library(readr)
# 1) Load enriched rat sightings
rats_sf <- sf::st_read("output/rats_enriched.geojson", quiet = TRUE) %>%
st_drop_geometry()
# 2) Assign each sighting to a quarter
rats_q <- rats_sf %>%
mutate(
call_date = ymd_hms(created_dt),
quarter   = floor_date(call_date, unit = "quarter")
) %>%
filter(!is.na(CD_ID))
# 3) Build capture history matrix
# Unique district IDs and occasions
districts <- sort(unique(rats_q$CD_ID))
occasions <- sort(unique(rats_q$quarter))
cap_hist <- rats_q %>%
group_by(CD_ID, quarter) %>%
summarise(calls = n(), .groups = "drop") %>%
complete(
CD_ID   = districts,
quarter = occasions,
fill    = list(calls = 0)
) %>%
arrange(match(CD_ID, districts), quarter) %>%
pivot_wider(
names_from  = quarter,
values_from = calls
)
# Convert to matrix for Stan (rows correspond to 'districts' vector)
count_matrix <- as.matrix(cap_hist[, as.character(occasions)])
# 4) Prepare data for Stan
stan_data <- list(
D = length(districts),
T = length(occasions),
y = count_matrix
)
# 5) Fit QHCR model
stan_mod <- rstan::stan_model("stan/qhcr_model.stan")
fit <- rstan::sampling(
object = stan_mod,
data   = stan_data,
iter   = 2000,
chains = 4,
cores  = parallel::detectCores()
)
# 6) Extract posterior summaries and map back to actual CD_ID values
# 'lambda[d]' in Stan corresponds to districts[d]
post <- as_draws_df(fit)
lambda_summ <- post %>%
select(starts_with("lambda[")) %>%
summarise_draws(
mean,
~quantile(.x, c(0.025, 0.975))
) %>%
rename(
estimate = mean,
lower    = `2.5%`,
upper    = `97.5%`
) %>%
# extract the Stan index, then map to the real CD_ID
mutate(
idx = as.integer(str_extract(variable, "(?<=\[)\d+(?=\])")),
# 031_qhcr_model.R
# -----------------------------------------------------------------------------
# Build quarterly QHCR model for rat abundance by Community District (CD_ID)
# Steps:
# 1) Read enriched sightings (with CD_ID)
# 2) Assign each sighting to a quarter
# 3) Build capture histories (counts) by CD_ID √ó quarter
# 4) Fit Stan-based QHCR model
# 5) Export posterior summaries to CSV (with correct CD_ID mapping)
# -----------------------------------------------------------------------------
# 0) Libraries
library(sf)
library(dplyr)
library(tidyr)
library(lubridate)
library(rstan)
library(posterior)
library(readr)
library(stringr)
# 1) Load enriched rat sightings
rats_sf <- sf::st_read(
"output/rats_enriched.geojson",
quiet = TRUE
) %>%
st_drop_geometry()
# 2) Assign each sighting to a quarter
rats_q <- rats_sf %>%
mutate(
call_date = ymd_hms(created_dt),  # parse the actual date-time field
quarter   = floor_date(call_date, unit = "quarter")
) %>%
filter(!is.na(CD_ID))
# 3) Build capture history matrix
districts <- sort(unique(rats_q$CD_ID))
occasions <- sort(unique(rats_q$quarter))
cap_hist <- rats_q %>%
group_by(CD_ID, quarter) %>%
summarise(calls = n(), .groups = "drop") %>%
complete(CD_ID = districts, quarter = occasions, fill = list(calls = 0)) %>%
arrange(match(CD_ID, districts), quarter) %>%
pivot_wider(names_from = quarter, values_from = calls)
# Convert to matrix for Stan
count_matrix <- as.matrix(cap_hist[, as.character(occasions)])
# 4) Prepare data for Stan
total_districts <- length(districts)
total_occasions <- length(occasions)
stan_data <- list(
D = total_districts,
T = total_occasions,
y = count_matrix
)
# 5) Fit QHCR model
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
stan_mod <- rstan::stan_model("stan/qhcr_model.stan")
fit <- rstan::sampling(
stan_mod,
data   = stan_data,
iter   = 2000,
chains = 4
)
# 6) Extract posterior summaries and map back to actual CD_ID values
# 'lambda[d]' in Stan corresponds to districts[d]
post <- as_draws_df(fit)
lambda_summ <- post %>%
select(starts_with("lambda[")) %>%
summarise_draws(
mean,
~quantile(.x, c(0.025, 0.975))
) %>%
rename(
estimate = mean,
lower    = `2.5%`,
upper    = `97.5%`
) %>%
mutate(
# extract the Stan index from variable name (e.g., "lambda[3]")
idx = as.integer(str_extract(variable, "(?<=\\[)\\d+(?=\\])")),
CD_ID = districts[idx]
) %>%
select(CD_ID, estimate, lower, upper)
# 7) Export to CSV
write_csv(lambda_summ, "output/district_qhcr.csv")
message("‚úÖ QHCR model complete ‚Äì wrote output/district_qhcr.csv")
readr::read_csv("output/district_qhcr.csv") %>% head()
# 031_qhcr_model.R
# -----------------------------------------------------------------------------
# Build quarterly QHCR model for rat abundance by Community District (CD_ID)
# Steps:
# 1) Read enriched sightings (with CD_ID)
# 2) Assign each sighting to a quarter
# 3) Build capture histories (counts) by CD_ID √ó quarter
# 4) Fit Stan-based QHCR model
# 5) Export posterior summaries to CSV (with correct CD_ID mapping)
# -----------------------------------------------------------------------------
# 0) Libraries
library(sf)
library(dplyr)
library(tidyr)
library(lubridate)
library(rstan)
library(posterior)
library(readr)
library(stringr)
# 1) Load enriched rat sightings
rats_sf <- sf::st_read(
"output/rats_enriched.geojson",
quiet = TRUE
) %>%
st_drop_geometry()
# 2) Assign each sighting to a quarter
rats_q <- rats_sf %>%
mutate(
call_date = ymd_hms(created_dt),  # parse the actual date-time field
quarter   = floor_date(call_date, unit = "quarter")
) %>%
filter(!is.na(CD_ID))
# 3) Build capture history matrix
districts <- sort(unique(rats_q$CD_ID))
occasions <- sort(unique(rats_q$quarter))
cap_hist <- rats_q %>%
group_by(CD_ID, quarter) %>%
summarise(calls = n(), .groups = "drop") %>%
complete(CD_ID = districts, quarter = occasions, fill = list(calls = 0)) %>%
arrange(match(CD_ID, districts), quarter) %>%
pivot_wider(names_from = quarter, values_from = calls)
# Convert to matrix for Stan
count_matrix <- as.matrix(cap_hist[, as.character(occasions)])
# 4) Prepare data for Stan
total_districts <- length(districts)
total_occasions <- length(occasions)
stan_data <- list(
D = total_districts,
T = total_occasions,
y = count_matrix
)
# 5) Fit QHCR model
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
stan_mod <- rstan::stan_model("stan/qhcr_model.stan")
fit <- rstan::sampling(
stan_mod,
data   = stan_data,
iter   = 2000,
chains = 4
)
# 6) Extract posterior summaries and map back to actual CD_ID values
# 'lambda[d]' in Stan corresponds to districts[d]
post <- as_draws_df(fit)
lambda_summ <- post %>%
select(starts_with("lambda[")) %>%
summarise_draws(
mean,
~quantile(.x, c(0.025, 0.975))
) %>%
rename(
estimate = mean,
lower    = `2.5%`,
upper    = `97.5%`
) %>%
mutate(
# extract the Stan index from variable name (e.g., "lambda[3]")
idx = as.integer(str_extract(variable, "(?<=\\[)\\d+(?=\\])")),
CD_ID = districts[idx]
) %>%
select(CD_ID, estimate, lower, upper)
# 7) Export to CSV
write_csv(lambda_summ, "output/district_qhcr.csv")
message("‚úÖ QHCR model complete ‚Äì wrote output/district_qhcr.csv")
