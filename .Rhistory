rats_clean <- rats_clean %>%
filter(!is.na(Longitude), !is.na(Latitude))
}
# 2) Convert to sf point geometry
rat_sf <- st_as_sf(
rats_clean,
coords = c("Longitude", "Latitude"),
crs    = 4326,
remove = FALSE
)
# 3) Read PLUTO parcels and repair invalid geometries
bbl_sf <- st_read("data/raw/MapPLUTO.shp") %>%
st_transform(crs = st_crs(rat_sf))
if (!all(st_is_valid(bbl_sf))) {
message("ðŸ”§ Repairing invalid PLUTO geometriesâ€¦")
bbl_sf <- sf::st_make_valid(bbl_sf)
}
# 4) Spatial-join: stamp each sighting with its BBL
rat_bbl <- st_join(
rat_sf,
bbl_sf %>% select(BBL),
join = st_within,
left = TRUE
)
# 5) Read in PLUTO & ACS tables (keyed by BBL)
pluto <- read_csv("data/raw/PLUTO.csv")
# 5) Read in PLUTO parcels (MapPLUTO.shp) for attributes
message("ðŸ”„ Reading PLUTO shapefile for attributesâ€¦")
pluto_sf <- st_read("data/raw/MapPLUTO.shp")
# 5b) Drop geometry to get the flat attribute table
pluto <- pluto_sf %>%
st_drop_geometry()
# 6) Read in ACS table (keyed by BBL)
message("ðŸ”„ Reading ACSÃ—BBL CSVâ€¦")
acs <- read_csv("data/raw/ACS.csv")
# 7) Attribute-join covariates to each sighting
rat_enriched <- rat_bbl %>%
left_join(pluto, by = "BBL") %>%
left_join(acs,   by = "BBL")
View(rat_bbl)
rlang::last_trace()
View(rat_bbl)
View(rats_clean)
View(rat_bbl)
# 0) Load required packages
library(sf)      # spatial data handling
library(dplyr)   # data wrangling
library(readr)   # CSV import
# 1) Read in your cleaned rats dataset
rats_clean <- read_csv("data/processed/rats_clean.csv")
# 1b) Drop any rows with missing coords
missing_n <- rats_clean %>%
filter(is.na(Longitude) | is.na(Latitude)) %>%
nrow()
if (missing_n > 0) {
message("âš  Dropping ", missing_n, " rows with missing Longitude/Latitude")
rats_clean <- rats_clean %>%
filter(!is.na(Longitude), !is.na(Latitude))
}
# 2) Convert to sf point geometry
rat_sf <- st_as_sf(
rats_clean,
coords = c("Longitude", "Latitude"),
crs    = 4326,
remove = FALSE
)
# 3) Read PLUTO parcels and repair invalid geometries
bbl_sf <- st_read("data/raw/MapPLUTO.shp") %>%
st_transform(crs = st_crs(rat_sf))
if (!all(st_is_valid(bbl_sf))) {
message("ðŸ”§ Repairing invalid PLUTO geometriesâ€¦")
bbl_sf <- sf::st_make_valid(bbl_sf)
}
# 4) Spatialâ€join, pulling BBL in under a temp name to avoid collision
rat_bbl <- st_join(
rat_sf,
bbl_sf %>% select(join_BBL = BBL),
join = st_within,
left = TRUE
) %>%
rename(BBL = join_BBL)
rlang::last_trace()
View(rat_bbl)
View(rats_clean)
pluto <- st_read("data/raw/MapPLUTO.shp") %>%
st_drop_geometry()
View(api)
view(census_api_key())
# 0) Load required packages
library(sf)      # spatial data handling
library(dplyr)   # data wrangling
library(readr)   # CSV import
# 1) Read in your cleaned rats dataset (kept intact)
rats_clean <- read_csv("data/processed/rats_clean.csv")
# 2) Create a joinâ€ready copy and drop its old BBL
rats_clean_join <- rats_clean %>%
select(-BBL)
# 2b) Drop any rows in the join copy with missing coords
missing_n <- rats_clean_join %>%
filter(is.na(Longitude) | is.na(Latitude)) %>%
nrow()
if (missing_n > 0) {
message("âš  Dropping ", missing_n, " rows with missing Longitude/Latitude")
rats_clean_join <- rats_clean_join %>%
filter(!is.na(Longitude), !is.na(Latitude))
}
# 3) Convert the join copy to sf point geometry
rat_sf <- st_as_sf(
rats_clean_join,
coords = c("Longitude", "Latitude"),
crs    = 4326,
remove = FALSE
)
# 4) Read PLUTO parcels and repair invalid geometries
bbl_sf <- st_read("data/raw/MapPLUTO.shp") %>%
st_transform(crs = st_crs(rat_sf))
if (!all(st_is_valid(bbl_sf))) {
message("ðŸ”§ Repairing invalid PLUTO geometriesâ€¦")
bbl_sf <- sf::st_make_valid(bbl_sf)
}
# 5) Spatialâ€join: bring in the parcel BBL under a temp name
rat_bbl <- st_join(
rat_sf,
bbl_sf %>% select(join_BBL = BBL),
join = st_within,
left = TRUE
) %>%
rename(BBL = join_BBL)
# 6) Read PLUTO attributes (directly from shapefile) and drop geometry
message("ðŸ”„ Reading PLUTO shapefile for attributesâ€¦")
pluto <- st_read("data/raw/MapPLUTO.shp") %>%
st_drop_geometry()
# 7) Read in ACS table (keyed by BBL)
message("ðŸ”„ Reading ACSÃ—BBL CSVâ€¦")
acs <- read_csv("data/raw/ACS.csv")
# 8) Attributeâ€join covariates to each sighting
rat_enriched <- rat_bbl %>%
left_join(pluto, by = "BBL") %>%
left_join(acs,   by = "BBL")
# 9) Ensure outputs folder exists
if (!dir.exists("outputs")) dir.create("outputs", recursive = TRUE)
# 10) Write out enriched GeoJSON
st_write(
rat_enriched,
"outputs/rat_clean.geojson",
driver     = "GeoJSON",
delete_dsn = TRUE
)
message("âœ… Spatial join complete: outputs/rat_clean.geojson written")
# 000_setup_cmdstanr.R
#
# This script gets **CmdStanR** up and running on Windows so you can compile
# and run Stan models from R.
#
# What happens, step by step:
#   1. Install the *R package* **cmdstanr** (one-time).
#   2. Make sure R can find a C++ compiler (comes with RTools).
#   3. Download & build the CmdStan C++ source (only first time; ~1 GB).
#   4. Compile the tiny built-in Bernoulli example model.
#   5. Run a quick 8-data-point MCMC sample to prove everything works.
#
# Re-running is safe: most steps notice theyâ€™re already done and skip.
# -----------------------------------------------------------------------------
# 1) Install cmdstanr if itâ€™s missing ------------------------------------------
if (!requireNamespace("cmdstanr", quietly = TRUE)) {
install.packages(
"cmdstanr",
repos = c("https://mc-stan.org/r-packages/", getOption("repos"))
)
} else {
message("cmdstanr already installed â€” nice!")
}
# 2) Load the package so we can call its helpers --------------------------------
library(cmdstanr)
# 3) Check that the C++ toolchain (gcc/make) is visible to R --------------------
#    `fix = TRUE` tries to patch common PATH problems for you.
cmdstanr::check_cmdstan_toolchain(fix = TRUE)
# 000_setup_cmdstanr.R
#
# This script gets **CmdStanR** up and running on Windows so you can compile
# and run Stan models from R.
#
# What happens, step by step:
#   1. Install the *R package* **cmdstanr** (one-time).
#   2. Make sure R can find a C++ compiler (comes with RTools).
#   3. Download & build the CmdStan C++ source (only first time; ~1 GB).
#   4. Compile the tiny built-in Bernoulli example model.
#   5. Run a quick 8-data-point MCMC sample to prove everything works.
#
# Re-running is safe: most steps notice theyâ€™re already done and skip.
# -----------------------------------------------------------------------------
# 1) Install cmdstanr if itâ€™s missing ------------------------------------------
if (!requireNamespace("cmdstanr", quietly = TRUE)) {
install.packages(
"cmdstanr",
repos = c("https://mc-stan.org/r-packages/", getOption("repos"))
)
} else {
message("cmdstanr already installed â€” nice!")
}
# 2) Load the package so we can call its helpers --------------------------------
library(cmdstanr)
# 3) Check that the C++ toolchain (gcc/make) is visible to R --------------------
#    `fix = TRUE` tries to patch common PATH problems for you.
cmdstanr::check_cmdstan_toolchain(fix = TRUE)
file.edit("~/.Renviron")
# 000_setup_cmdstanr.R
#
# This script gets **CmdStanR** up and running on Windows so you can compile
# and run Stan models from R.
#
# What happens, step by step:
#   1. Install the *R package* **cmdstanr** (one-time).
#   2. Make sure R can find a C++ compiler (comes with RTools).
#   3. Download & build the CmdStan C++ source (only first time; ~1 GB).
#   4. Compile the tiny built-in Bernoulli example model.
#   5. Run a quick 8-data-point MCMC sample to prove everything works.
#
# Re-running is safe: most steps notice theyâ€™re already done and skip.
# -----------------------------------------------------------------------------
# 1) Install cmdstanr if itâ€™s missing ------------------------------------------
if (!requireNamespace("cmdstanr", quietly = TRUE)) {
install.packages(
"cmdstanr",
repos = c("https://mc-stan.org/r-packages/", getOption("repos"))
)
} else {
message("cmdstanr already installed â€” nice!")
}
# 2) Load the package so we can call its helpers --------------------------------
library(cmdstanr)
# 3) Check that the C++ toolchain (gcc/make) is visible to R --------------------
#    `fix = TRUE` tries to patch common PATH problems for you.
cmdstanr::check_cmdstan_toolchain(fix = TRUE)
# 000_setup_cmdstanr.R
#
# This script gets **CmdStanR** up and running on Windows so you can compile
# and run Stan models from R.
#
# What happens, step by step:
#   1. Install the *R package* **cmdstanr** (one-time).
#   2. Make sure R can find a C++ compiler (comes with RTools).
#   3. Download & build the CmdStan C++ source (only first time; ~1 GB).
#   4. Compile the tiny built-in Bernoulli example model.
#   5. Run a quick 8-data-point MCMC sample to prove everything works.
#
# Re-running is safe: most steps notice theyâ€™re already done and skip.
# -----------------------------------------------------------------------------
# 1) Install cmdstanr if itâ€™s missing ------------------------------------------
if (!requireNamespace("cmdstanr", quietly = TRUE)) {
install.packages(
"cmdstanr",
repos = c("https://mc-stan.org/r-packages/", getOption("repos"))
)
} else {
message("cmdstanr already installed â€” nice!")
}
# 2) Load the package so we can call its helpers --------------------------------
library(cmdstanr)
# 3) Check that the C++ toolchain (gcc/make) is visible to R --------------------
#    `fix = TRUE` tries to patch common PATH problems for you.
cmdstanr::check_cmdstan_toolchain(fix = TRUE)
Sys.getenv("RTOOLS44_HOME")
cmdstanr::check_cmdstan_toolchain()
# Master driver that runs the entire ratâ€‘data pipeline **in order** and checks
# that every expected artefact is created. Handy for fresh environments or CI.
#
# Outline
# 0. (Optional) setwd() to the repo root.
# 1. Define the ordered vector of R scripts to source.
# 2. Loop through and `source()` each, echoing output.
# 3. Assert that the key CSV / GeoJSON files exist.
# ---------------------------------------------------------------------------
## 0) Working directory -------------------------------------------------------
# Uncomment and edit if you intend to run this outside the project root.
# setwd("C:/path/to/nyc-rat-abundance")
## 1) Scripts to run (ordered) -------------------------------------------------
scripts <- c(
"scripts/000_setup_cmdstanr.R",
"scripts/011_data_prep.R",
"scripts/012_data_prep_derivation.R",  # makes rats_ready + borough_rates
"scripts/021_acs_fetch.R",             # BBLâ€‘keyed ACS lookup
"scripts/022_spatial_join.R",          # adds PLUTO & ACS to rat points
"scripts/023_income_scatter.R",        # tractâ€‘level scatter data
"scripts/024_bg_acs_join.R"            # BGâ€‘level join & summary
)
## 2) Run each script, stop on error -----------------------------------------
for (s in scripts) {
message("ðŸ”„  Running ", s, " â€¦")
source(s, echo = TRUE)
}
## 5) Spatial join lots â†’ rat points to grab BBL -------------------------------
#    Keep only the BBL column from PLUTO at this stage (lighter memory).
rat_bbl <- st_join(
rat_sf,
bbl_sf %>% select(join_BBL = BBL),
join = st_within,   # point must fall *inside* lot polygon
left = TRUE         # keep all rat points even if no lot (e.g., parks, water)
) %>%
rename(BBL = join_BBL)
# Enrich each cleaned rat sighting with parcel (PLUTO) attributes **and** ACS
# blockâ€‘group socioeconomic metrics. Result is a readyâ€‘toâ€‘map GeoJSON.
#
# Workflow
#   1. Read `rats_clean.csv` (already flagged & filtered).
#   2. Convert to an sf points object.
#   3. Spatialâ€‘join to MapPLUTO to recover the taxâ€‘lot ID (BBL).
#   4. Bring in full PLUTO attributes and a preâ€‘built `ACS.csv` keyed by BBL.
#   5. Write one tidy GeoJSON.
#
# Assumes you have already run 021_acs_fetch.R so `ACS.csv` exists.
# -----------------------------------------------------------------------------
## 0) Libraries ----------------------------------------------------------------
library(sf)      # spatial data
library(dplyr)   # %>% and verbs
library(readr)   # read_csv(), write_csv()
## 1) Load cleaned rats data ----------------------------------------------------
rats_clean <- read_csv("data/processed/rats_clean.csv")
## 2) Remove stale BBL col (weâ€™ll reâ€‘attach a fresh one) ------------------------
rats_clean_join <- rats_clean %>% select(-BBL)
# 2b) Drop rows without coordinates â€“ canâ€™t map what we canâ€™t locate
missing_n <- rats_clean_join %>%
filter(is.na(Longitude) | is.na(Latitude)) %>%
nrow()
if (missing_n > 0) {
message("âš   Dropping ", missing_n, " rows without coordinates")
rats_clean_join <- rats_clean_join %>%
filter(!is.na(Longitude), !is.na(Latitude))
}
## 3) Cast to sf points ---------------------------------------------------------
rat_sf <- st_as_sf(
rats_clean_join,
coords = c("Longitude", "Latitude"),
crs    = 4326,   # WGS84
remove = FALSE
)
## 4) Read PLUTO parcels & ensure valid geometries -----------------------------
bbl_sf <- st_read("data/raw/MapPLUTO.shp", quiet = TRUE) %>%
st_transform(crs = st_crs(rat_sf))
if (!all(st_is_valid(bbl_sf))) {
message("ðŸ”§  Fixing invalid PLUTO polygons â€¦")
bbl_sf <- st_make_valid(bbl_sf)
}
## 5) Spatial join lots â†’ rat points to grab BBL -------------------------------
#    Keep only the BBL column from PLUTO at this stage (lighter memory).
rat_bbl <- st_join(
rat_sf,
bbl_sf %>% select(join_BBL = BBL),
join = st_within,   # point must fall *inside* lot polygon
left = TRUE         # keep all rat points even if no lot (e.g., parks, water)
) %>%
rename(BBL = join_BBL)
## 6) Load full PLUTO attributes (no geometry needed) --------------------------
pluto_attrs <- st_read("data/raw/MapPLUTO.shp", quiet = TRUE) %>%
st_drop_geometry()
## 7) Load ACS metrics keyed by BBL --------------------------------------------
acs <- read_csv("data/processed/ACS.csv")
## 8) Attribute joins -----------------------------------------------------------
rat_enriched <- rat_bbl %>%
left_join(pluto_attrs, by = "BBL") %>%
left_join(acs,         by = "BBL")
## 9) Ensure output dir exists --------------------------------------------------
output_dir <- "output"
if (!dir.exists(output_dir)) dir.create(output_dir, recursive = TRUE)
## 10) Write GeoJSON ------------------------------------------------------------
output_path <- file.path(output_dir, "rats_enriched.geojson")
st_write(rat_enriched, output_path, driver = "GeoJSON", delete_dsn = TRUE)
message("âœ…  Spatial join complete â€“ wrote " , output_path)
## 0) Libraries ----------------------------------------------------------------
# install.packages(c("sf", "dplyr", "readr", "stringr"))
library(sf)
library(dplyr)
# Build a tractâ€‘level table that pairs ratâ€‘call rates with median household
# income â€“ exactly what the Tableau scatter plot needs.
#
# Steps
#   1. Read the fully enriched rat GeoJSON (has GEOID + PLUTO + ACS columns).
#   2. Count calls per *tract* (first 11 chars of the 12â€‘digit GEOID).
#   3. Load the BBLâ€‘keyed ACS lookup and roll it up from BG â†’ tract.
#   4. Join calls + income, compute callsâ€‘perâ€‘10k residents.
#   5. Write a slim CSV for Tableau.
# -----------------------------------------------------------------------------
## 0) Libraries ----------------------------------------------------------------
# install.packages(c("sf", "dplyr", "readr", "stringr"))
library(sf)
library(dplyr)
library(readr)
library(stringr)
## 1) Read rat sightings with GEOID -------------------------------------------
#    Note: earlier script writes *rats_enriched.geojson* â€“ make sure the path
#    matches. If not, adjust the filename below.
rats_enriched <- st_read("output/rats_enriched.geojson", quiet = TRUE)
## 2) Calls per tract -----------------------------------------------------------
calls_by_tract <- rats_enriched %>%
mutate(
tract = str_sub(GEOID, 1, 11)  # GEOID[1:11] = state + county + tract
) %>%
st_drop_geometry() %>%           # stats only; no need for shapes
count(tract, name = "calls")
## 3) ACS metrics per block group ---------------------------------------------
acs_bbl <- read_csv("data/processed/ACS.csv")
bg_acs <- acs_bbl %>%
distinct(GEOID, pop_tot, med_income) %>%   # one row per BG
mutate(
tract = str_sub(GEOID, 1, 11)
)
## 4) Aggregate BG â†’ tract ------------------------------------------------------
tract_acs <- bg_acs %>%
group_by(tract) %>%
summarise(
pop_tot = sum(pop_tot, na.rm = TRUE),
# Weighted mean: (Î£ med_income * pop) / Î£ pop
med_income = sum(med_income * pop_tot, na.rm = TRUE) / sum(pop_tot, na.rm = TRUE)
) %>%
ungroup()
## 5) Combine calls + demographics --------------------------------------------
income_scatter_df <- calls_by_tract %>%
left_join(tract_acs, by = "tract") %>%
filter(pop_tot > 0) %>%
mutate(
rate_per_10k = calls / pop_tot * 10000
)
## 6) Save CSV for Tableau ------------------------------------------------------
write_csv(income_scatter_df, "output/income_scatter.csv")
message("âœ…  Wrote ", nrow(income_scatter_df), " tracts to output/income_scatter.csv")
# 024_bg_acs_join.R ------------------------------------------------------------
#
# Goal
# ----
# 1. Attach ACS blockâ€‘group socioeconomic columns (population, median income,
#    poverty count) to **each** rat sighting (pointâ€‘level).
# 2. Summarise at the blockâ€‘group level to get calls + callâ€‘rate per 10â€¯000.
# 3. Save both products for Tableau: a point CSV and a BG summary CSV.
#
# Prereqs
# â€¢ You ran 022_spatial_join.R â†’ `output/rats_enriched.geojson` exists.
# â€¢ You have a Census API key in the envâ€‘var `CENSUS_API_KEY`.
# -----------------------------------------------------------------------------
## 0) Libraries ---------------------------------------------------------------
# install.packages(c("sf", "dplyr", "readr", "stringr", "tidycensus"))
library(sf)
library(dplyr)
library(readr)
library(stringr)
library(tidycensus)
## 1) Download 2023 ACS blockâ€‘group stats --------------------------------------
census_api_key(Sys.getenv("CENSUS_API_KEY"), install = FALSE)
vars <- c(
pop_tot    = "B01003_001",  # total population
med_income = "B19013_001",  # median household income (USD)
pov_count  = "B17010_002"   # persons below poverty
)
message("ðŸ“¥  Pulling 2023 ACS blockâ€‘group data â€¦")
acs_bg <- get_acs(
geography = "block group",
variables = vars,
year      = 2023,
state     = "NY",
county    = c("Bronx", "Kings", "New York", "Queens", "Richmond"),
output    = "wide",
geometry  = TRUE
) %>%
rename_with(~ str_remove(.x, "E$"), ends_with("E")) %>%  # drop trailing E
select(GEOID, pop_tot, med_income, pov_count) %>%
st_transform(crs = 4326)  # match rat points (WGS84)
## 2) Load enriched rat points --------------------------------------------------
message("ðŸ“¥  Reading rats_enriched.geojson â€¦")
rats <- st_read("output/rats_enriched.geojson", quiet = TRUE)
## 3) Spatial join rats â†’ block groups -----------------------------------------
message("ðŸ”—  Joining rat points to BGs â€¦")
rat_bg_join <- st_join(
rats,
acs_bg,
join = st_intersects,  # includes boundaryâ€‘touching points
left = TRUE
) %>%
rename_with(~ str_remove(.x, "\\.y$"), ends_with(".y")) %>%  # keep clean names
select(-ends_with(".x"))
## 4) Write pointâ€‘level CSV -----------------------------------------------------
rat_bg_point_df <- st_drop_geometry(rat_bg_join)
write_csv(rat_bg_point_df, "output/rat_with_bg_ACS_point.csv")
message("âœ…  Saved pointâ€‘level rat+ACS â†’ output/rat_with_bg_ACS_point.csv (",
scales::comma(nrow(rat_bg_point_df)), " rows)")
## 5) Summarise by block group --------------------------------------------------
message("ðŸ“Š  Building BGâ€‘level summary â€¦")
bg_summary <- rat_bg_point_df %>%
group_by(GEOID) %>%
summarise(
calls      = n(),
pop_tot    = first(pop_tot),    # identical within BG
med_income = first(med_income),
pov_count  = first(pov_count)
) %>%
ungroup() %>%
mutate(rate_per_10k = calls / pop_tot * 10000)
write_csv(bg_summary, "output/bg_calls_ACS_summary.csv")
message("âœ…  Saved BG summary â†’ output/bg_calls_ACS_summary.csv (",
scales::comma(nrow(bg_summary)), " rows)")
View(rat_sf)
View(rat_sf)
View(rats)
View(acs_by_bbl)
View(acs)
View(acs_by_bbl)
View(acs)
View(acs_bbl)
View(acs_bg)
View(bbl_pts)
View(data_list)
gc()
View(rats)
View(rats_enriched)
